{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe54c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from typing import List, Dict, Optional, Tuple, Set \n",
    "from collections import deque, defaultdict\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a217e76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admin', 'config', 'graph_db', 'local', 'prerequisites_graph', 'test_graph_retriever', 'testing-mcts', 'vectorstore']\n"
     ]
    }
   ],
   "source": [
    "client = MongoClient(\"localhost\", 27017)\n",
    "print(client.list_database_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d3b44a",
   "metadata": {},
   "source": [
    "## Graph DB\n",
    "Creación de una base de datos de grafos usando Python y MongoDB, esta incluye la estructura de datos, las operaciones básicas y la función para recuperar entidades adyacentes.\n",
    "\n",
    "La clase `GraphDB` maneja toda la lógica de la base de datos de grafos. Utiliza dos colecciones:\n",
    "- `nodes`: para almacenar las entidades del grafo\n",
    "- `edges`: para almacenar las relaciones entre entidades\n",
    "\n",
    "Dicha clase trae las siguientes funcionalidades:\n",
    "- `get_adjacent_entities`: recupera las entidades adyacentes a un nodo dado, con opciones para:\n",
    "  - Filtrar por tipo de relación\n",
    "  - Especificar dirección (grafo dirigido)\n",
    "  - Obtener información completa de cada entidad adyacente\n",
    "- `add_node`: añade un nodo (entidad) al grafo definiendo el identificador único del nodo, el tipo de nodo y las propiedades adicionales del nodo\n",
    "- `del_node`: elimina un nodo del grafo y elimina automáticamente todas las relaciones donde el nodo participa (`cascade=True`)\n",
    "- `add_edge`: añade una arista (relación) entre dos nodos, definiendo:\n",
    "  - Nodo origen\n",
    "  - Nodo destino\n",
    "  - Tipo de relación \n",
    "  - Propiedades de la relación\n",
    "  - Una variable booleana que determina si la relación es dirigida o no\n",
    "- `get_relationship_types`: devuelve todos los tipos de relaciones únicas en el grafo\n",
    "- `get_node_types`: devuelve todos los tipos de nodos únicos en el grafo \n",
    "- `get_graph_stats`: devuelve las estadísticas básicas del grafo, incluyendo:\n",
    "  - Número de nodos \n",
    "  - Número de aristas\n",
    "  - Todos los tipos de nodos únicos (`get_node_types`)\n",
    "  - Todos los tipos de relaciones únicas (`get_relationship_types`)\n",
    "- `_create_indexes`: crea índices en MongoDB para optimizar las consultas de la base de datos de grafos. Para cada colección:\n",
    "  - `nodes`:\n",
    "    - `node_id`: permite búsquedas por un identificador y garantiza unicidad\n",
    "    - `type`: optimiza filtros por tipo de nodo\n",
    "  - `edges`:\n",
    "    - `[source, target]`: índice compuesto para consultas con ambos campos\n",
    "    - `source`: búsquedas rápidas por nodo origen\n",
    "    - `target`: búsquedas rápidas por nodo destino\n",
    "    - `relation_type`: filtros por tipo de relación\n",
    "\n",
    "> Esta clase soporta grafos dirigidos y no dirigidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faf0b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDB:\n",
    "  \n",
    "  def __init__(self, db_name:str = \"graph_db\", host:str = \"localhost\", port:int = 27017) -> None:\n",
    "    \"\"\"Inicializa la conexión a MongoDB y crea las colecciones necesarias\n",
    "\n",
    "    Args:\n",
    "        db_name (str, optional): nombre de la base de datos. Defaults to \"graph_db\".\n",
    "        host (str, optional): host de mongodb. Defaults to \"localhost\".\n",
    "        port (int, optional): puerto de mongodb. Defaults to 27017.\n",
    "    \"\"\"\n",
    "    \n",
    "    self.client:MongoClient = MongoClient(host,port)\n",
    "    self.db = self.client[db_name]\n",
    "    \n",
    "    # colecciones\n",
    "    self.nodes = self.db.nodes # entidades/nodos del grafo\n",
    "    self.edges = self.db.edges # relaciones/aristas del grafo\n",
    "    \n",
    "    # crear indices para mejorar el rendimiento\n",
    "    self._create_indexes()\n",
    "  \n",
    "  def _create_indexes(self):\n",
    "    \"Crea índices para optimizar las consultas\"\n",
    "    # índices para nodos\n",
    "    self.nodes.create_index(\"node_id\", unique=True)\n",
    "    self.nodes.create_index(\"type\")\n",
    "    \n",
    "    # índices para aristas\n",
    "    self.edges.create_index([(\"source\", 1), (\"target\", 1)])\n",
    "    self.edges.create_index(\"source\")\n",
    "    self.edges.create_index(\"target\")\n",
    "    self.edges.create_index(\"relation_type\")\n",
    "  \n",
    "  def add_node(self, node_id:str, node_type:str, properties:Dict = None) -> bool:\n",
    "    \"\"\"Añade un nodo al grafo\n",
    "  \n",
    "    Args:\n",
    "        node_id (str): identificador único del nodo\n",
    "        node_type (str): tipo de nodo\n",
    "        properties (Dict, optional): propiedades adicionales del nodo. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        bool: True si se añadió correctamente, False en caso contrario\n",
    "    \"\"\"\n",
    "    if properties is None: properties = { }\n",
    "    \n",
    "    node_doc = {\n",
    "      \"node_id\": node_id,\n",
    "      \"type\": node_type,\n",
    "      \"properties\": properties\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "      self.nodes.insert_one(node_doc)\n",
    "      return True\n",
    "    except Exception as e:\n",
    "      print(f\"Error al insertar nodo: {e}\")\n",
    "      return False\n",
    "  \n",
    "  def del_node(self, node_id:str, cascade: bool = True) -> Dict:\n",
    "    \"\"\"Elimina un nodo del grafo\n",
    "\n",
    "    Args:\n",
    "        node_id (str): ID del nodo a eliminar\n",
    "        cascade (bool, optional): Si True, elimina también todas las relaciones del nodo. Si False, solo elimina el nodo si no tiene relaciones. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        Dict: Resultado de la operación de eliminación\n",
    "    \"\"\"\n",
    "    if not self._node_exists(node_id=node_id):\n",
    "      return {\n",
    "        \"success\": False,\n",
    "        \"message\": f\"El nodo {node_id} no existe\",\n",
    "        \"nodes_deleted\": 0,\n",
    "        \"edges_deleted\": 0,\n",
    "        \"existing_edges\": 0,\n",
    "      }\n",
    "    \n",
    "    # contar relaciones existentes\n",
    "    outgoing_edges = self.edges.count_documents({\"source\": node_id})\n",
    "    incoming_edges = self.edges.count_documents({\"target\": node_id})\n",
    "    total_edges = outgoing_edges + incoming_edges\n",
    "    \n",
    "    # si cascade es False y tiene relaciones, no eliminar\n",
    "    if not cascade and total_edges > 0:\n",
    "      return {\n",
    "        \"success\": False,\n",
    "        \"message\": f\"El nodo {node_id} tiene {total_edges} relaciones. Para eliminar el nodo con las conexiones se debe usar cascade=True\",\n",
    "        \"nodes_deleted\": 0,\n",
    "        \"edges_deleted\": 0,\n",
    "        \"existing_edges\": total_edges\n",
    "      }\n",
    "    \n",
    "    try:\n",
    "      # eliminar todas las relaciones donde el nodo es origen o destino\n",
    "      edges_deleted = 0\n",
    "      if cascade:\n",
    "        # eliminar aristas donde es origen (source)\n",
    "        result_outgoing = self.edges.delete_many({\"source\":node_id})\n",
    "        # eliminar aristas donde es destino (target)\n",
    "        result_incoming = self.edges.delete_many({\"target\":node_id})\n",
    "        edges_deleted = result_outgoing.deleted_count + result_incoming.deleted_count\n",
    "      \n",
    "      # eliminar el nodo\n",
    "      result_node = self.nodes.delete_one({\"node_id\": node_id})\n",
    "      nodes_deleted = result_node.deleted_count\n",
    "      \n",
    "      return {\n",
    "        \"success\": True,\n",
    "        \"message\": f\"Node {node_id} eliminado con exito\",\n",
    "        \"nodes_deleted\": nodes_deleted,\n",
    "        \"edges_deleted\": edges_deleted,\n",
    "        \"existing_edges\": 0\n",
    "      }\n",
    "    except Exception as e:\n",
    "      return {\n",
    "        \"success\": False,\n",
    "        \"message\": f\"Error al eliminar nodo: {str(e)}\",\n",
    "        \"nodes_deleted\": 0,\n",
    "        \"edges_deleted\": 0,\n",
    "        \"existing_edges\": 0\n",
    "      }\n",
    "  \n",
    "  def add_edge(self, source_id:str, target_id:str, relation_type:str,\n",
    "              properties: Dict = None, directed: bool = True) -> Dict:\n",
    "    \"\"\"Añade una arista (relación) entre dos nodos. Previene la creación de aristas exactamente iguales\n",
    "\n",
    "    Args:\n",
    "        source_id (str): ID del nodo origen\n",
    "        target_id (str): ID del nodo destino\n",
    "        relation_type (str): Tipo de relación (ej: 'knows', 'works_at', etc)\n",
    "        properties (Dict, optional): Propiedades adicionales de la relación. Defaults to None.\n",
    "        directed (bool, optional): Si la relación es dirigida o no. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        Dict: Resultado de la operación\n",
    "    \"\"\"\n",
    "    if properties is None:\n",
    "      properties = { }\n",
    "    \n",
    "    # verificar que ambos nodos existen\n",
    "    if not self._node_exists(source_id) or not self._node_exists(target_id):\n",
    "      return {\n",
    "        \"success\": False,\n",
    "        \"message\": \"Error: Uno o ambos nodos no existen\",\n",
    "        \"edge_created\": False,\n",
    "        \"duplicate_found\": False\n",
    "      }\n",
    "    \n",
    "    # verificar si la arista ya existe\n",
    "    existing_edge = self._edge_exists(source_id, target_id, relation_type, properties, directed)\n",
    "    if existing_edge:\n",
    "      return {\n",
    "        \"success\": False,\n",
    "        \"message\": f\"La arista ya existe: {source_id} -> {target_id} ({relation_type})\",\n",
    "        \"edge_created\": False,\n",
    "        \"duplicate_found\": True,\n",
    "        \"existing_edge_id\": str(existing_edge[\"_id\"])\n",
    "      }\n",
    "    \n",
    "    edge_doc = {\n",
    "      \"source\": source_id,\n",
    "      \"target\": target_id,\n",
    "      \"relation_type\": relation_type,\n",
    "      \"properties\": properties,\n",
    "      \"directed\": directed\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "      # insertar relación source_id -> target_id\n",
    "      result = self.edges.insert_one(edge_doc)\n",
    "      edges_created = 1\n",
    "      \n",
    "      # si no es dirigido, crear la relación inversa (target_id -> source_id)\n",
    "      reverse_created = False \n",
    "      if not directed:\n",
    "        # verificar si la relación inversa ya existe\n",
    "        reverse_existing = self._edge_exists(target_id, source_id, relation_type, properties, directed)\n",
    "        if not reverse_existing:\n",
    "          reverse_edge = {\n",
    "            \"source\": target_id,\n",
    "            \"target\": source_id,\n",
    "            \"relation_type\": relation_type,\n",
    "            \"properties\": properties,\n",
    "            \"directed\": False\n",
    "          } \n",
    "          self.edges.insert_one(reverse_edge)\n",
    "          edges_created += 1\n",
    "          reverse_created = True\n",
    "      \n",
    "      return {\n",
    "        \"success\": True,\n",
    "        \"message\": f\"Arista creada exitosamente: {source_id} -> {target_id} ({relation_type})\",\n",
    "        \"edge_created\": True,\n",
    "        \"duplicate_found\": False,\n",
    "        \"edge_id\": str(result.inserted_id),\n",
    "        \"edges_created\": edges_created,\n",
    "        \"reverse_created\": reverse_created\n",
    "      }  \n",
    "      \n",
    "    except Exception as e:\n",
    "      return {\n",
    "        \"success\": False,\n",
    "        \"message\": f\"Error al insertar arista: {str(e)}\",\n",
    "        \"edge_created\": False,\n",
    "        \"duplicate_found\": False\n",
    "      }\n",
    "  \n",
    "  def _node_exists(self, node_id:str) -> bool:\n",
    "    \"Verifica si un nodo existe\"\n",
    "    return self.nodes.find_one({\"node_id\":node_id}) is not None\n",
    "  \n",
    "  def _edge_exists(self, source_id:str, target_id:str, relation_type:str, properties:Dict, directed:bool) -> Optional[Dict]:\n",
    "    \"\"\"Verifica si una arista exactamente igual ya existe\n",
    "\n",
    "    Args:\n",
    "        source_id (str): ID del nodo origen\n",
    "        target_id (str): ID del nodo destino\n",
    "        relation_type (str): tipo de relación\n",
    "        properties (Dict): propiedades de la relación\n",
    "        directed (bool): si la relación es dirigida\n",
    "\n",
    "    Returns:\n",
    "        Dict: Información de la arista existente o None si no existe\n",
    "    \"\"\"\n",
    "    query = {\n",
    "      \"source\": source_id,\n",
    "      \"target\": target_id,\n",
    "      \"relation_type\": relation_type,\n",
    "      \"properties\": properties,\n",
    "      \"directed\": directed\n",
    "    }\n",
    "    return self.edges.find_one(query)\n",
    "  \n",
    "  def get_adjacent_entities(self, node_id:str, relation_filter:str = None, direction:str = \"both\") -> List[Dict]:\n",
    "    \"\"\"Recupera las entidades adyacentes a un nodo dado\n",
    "\n",
    "    Args:\n",
    "        node_id (str): ID del nodo del cual se quiere obtener las entidades adyacentes\n",
    "        relation_filter (str, optional): Filtro opcional por tipo de relación . Defaults to None.\n",
    "        direction (str, optional): Dirección de las relacciones ('outgoing', 'incoming', defaults='both')\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: Lista de diccionarios con información de entidades adyacentes\n",
    "    \"\"\"\n",
    "    if not self._node_exists(node_id):\n",
    "      print(f\"Error: El nodo {node_id} no existe\")\n",
    "      return []\n",
    "    \n",
    "    query_conditions = []\n",
    "    \n",
    "    # Relaciones salientes (este nodo es el origen)\n",
    "    if direction in [\"outgoing\", \"both\"]:\n",
    "      outgoing_query = {\"source\":node_id}\n",
    "      if relation_filter: outgoing_query[\"relation_type\"] = relation_filter\n",
    "      query_conditions.append(outgoing_query)\n",
    "      \n",
    "    # Relaciones entrantes (este nodo es el destino)\n",
    "    if direction in [\"incoming\", \"both\"]:\n",
    "      incoming_query = {\"target\":node_id}\n",
    "      if relation_filter: incoming_query[\"relation_type\"] = relation_filter \n",
    "      query_conditions.append(incoming_query)\n",
    "    \n",
    "    adjacent_entities:List = []\n",
    "    if query_conditions:\n",
    "      if len(query_conditions) == 1:\n",
    "        edges_cursor = self.edges.find(query_conditions[0])\n",
    "      else:\n",
    "        edges_cursor = self.edges.find( {\"$or\": query_conditions} )\n",
    "      \n",
    "      for edge in edges_cursor:\n",
    "        # determinar cuál es la entidad adyacente\n",
    "        if edge[\"source\"] == node_id:\n",
    "          adjacent_id = edge[\"target\"]\n",
    "          relationship_direction = \"outgoing\"\n",
    "        else: \n",
    "          adjacent_id = edge[\"source\"]\n",
    "          relationship_direction = \"incoming\"\n",
    "        \n",
    "        # obtener información de la entidad adyacente\n",
    "        adjacent_node = self.nodes.find_one( {\"node_id\": adjacent_id} )\n",
    "        \n",
    "        if adjacent_node:\n",
    "          adjacent_info = {\n",
    "            \"node_id\": adjacent_node[\"node_id\"],\n",
    "            \"type\": adjacent_node[\"type\"],\n",
    "            \"properties\": adjacent_node[\"properties\"],\n",
    "            \"relationship\": {\n",
    "              \"type\": edge[\"relation_type\"],\n",
    "              \"direction\": relationship_direction,\n",
    "              \"properties\": edge[\"properties\"],\n",
    "              \"directed\": edge[\"directed\"]\n",
    "            }\n",
    "          }\n",
    "          adjacent_entities.append(adjacent_info)\n",
    "    \n",
    "    return adjacent_entities  \n",
    "\n",
    "  def get_node_info(self, node_id:str) -> Optional[Dict]:\n",
    "    \"\"\"Obtiene información completa del nodo\n",
    "    \n",
    "    Args:\n",
    "        node_id (str): ID del nodo\n",
    "\n",
    "    Returns:\n",
    "        Optional[Dict]: Información del nodo o None si no existe\n",
    "    \"\"\"\n",
    "    node = self.nodes.find_one({\"node_id\":node_id})\n",
    "    if node:\n",
    "      # remover el _id de MongoDB para una salida más limpia\n",
    "      del node['_id']\n",
    "      return node \n",
    "    return None\n",
    "  \n",
    "  def get_relationship_types(self) -> List[str]:\n",
    "    \"Obtiene todos los tipos de relaciones únicas en el grafo\"\n",
    "    return self.edges.distinct(\"relation_type\")\n",
    "  \n",
    "  def get_node_types(self) -> List[str]:\n",
    "    \"Obtiene todos los tipos de nodos únicos en el grafo\"\n",
    "    return self.nodes.distinct(\"type\")\n",
    "  \n",
    "  def get_graph_stats(self) -> Dict:\n",
    "    \"Obtiene estadísticas básicas del grafo\"\n",
    "    return {\n",
    "      \"total_nodes\": self.nodes.count_documents({}),\n",
    "      \"total_edges\": self.edges.count_documents({}),\n",
    "      \"node_types\": self.get_node_types(),\n",
    "      \"relationship_types\": self.get_relationship_types()\n",
    "    }\n",
    "  \n",
    "  def retriever(self) -> ... :\n",
    "    pass \n",
    "  \n",
    "  def clear_database(self, confirm:bool = False) -> Dict:\n",
    "    \"\"\"Elimina toda la información de la base de datos (todos los nodos y aristas) \n",
    "    \n",
    "    Args:\n",
    "        confirm (bool, optional): Debe ser True para confirmar la eliminación total. Esto previene eliminaciones accidentales. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        Dict: Resultado de la operación con las estadísticas de la eliminación\n",
    "    \"\"\"\n",
    "    if not confirm:\n",
    "      return {\n",
    "        \"success\": False,\n",
    "        \"message\": \"Eliminación cancelada. Use confirm=True para confirmar la eliminación total de la base de datos\",\n",
    "        \"nodes_deleted\": 0,\n",
    "        \"edges_deleted\": 0,\n",
    "        \"warning\": \"Esta operación eliminará TODOS los datos permanentemente\"\n",
    "      }\n",
    "    \n",
    "    try: \n",
    "      # Obtener estadísticas antes de eliminar\n",
    "      initial_stats = self.get_graph_stats()\n",
    "      \n",
    "      # Eliminar todas las aristas\n",
    "      edges_result = self.edges.delete_many({})\n",
    "      edges_deleted = edges_result.deleted_count\n",
    "      \n",
    "      # Eliminar todos los nodos\n",
    "      nodes_result = self.nodes.delete_many({})\n",
    "      nodes_deleted = nodes_result.deleted_count\n",
    "      \n",
    "      # Verificar que las colecciones estén vacías\n",
    "      remaining_nodes = self.nodes.count_documents({})\n",
    "      remaining_edges = self.edges.count_documents({})\n",
    "      \n",
    "      return {\n",
    "        \"success\": True,\n",
    "        \"message\": \"Base de datos limpiada con exito\",\n",
    "        \"nodes_deleted\": nodes_deleted,\n",
    "        \"edges_deleted\": edges_deleted,\n",
    "        \"initial_stats\": initial_stats,\n",
    "        \"remaining_nodes\": remaining_nodes,\n",
    "        \"remaining_edges\": remaining_edges,\n",
    "        \"database_empty\": remaining_nodes == 0 and remaining_edges == 0\n",
    "      }\n",
    "    except Exception as e:\n",
    "      return {\n",
    "        \"success\": False,\n",
    "        \"message\": f\"Error al limpiar la base de datos: {str(e)}\",\n",
    "        \"nodes_deleted\": 0,\n",
    "        \"edges_deleted\": 0\n",
    "      }\n",
    "  \n",
    "  def reset_database(self, confirm:bool = False) -> Dict:\n",
    "    \"\"\"Reinicia completamente la base de datos: elimina todo y recrea los índices\n",
    "\n",
    "    Args:\n",
    "        confirm (bool): Debe ser True para confirmar el reinicio total. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        Dict: Resultado de la operación\n",
    "    \"\"\"\n",
    "    if not confirm:\n",
    "      return {\n",
    "        \"success\": False,\n",
    "        \"message\": \"Reinicio cancelado. Use confirm=True para confirmar el reinicio total de la base de datos\",\n",
    "        \"warning\": \"Esta operación eliminará TODOS los datos y recreará los índices\"\n",
    "      }\n",
    "    try:\n",
    "      # Limpiar todos los datos\n",
    "      clear_result = self.clear_database(confirm=True)\n",
    "      \n",
    "      if not clear_result[\"success\"]:\n",
    "        return clear_result\n",
    "      \n",
    "      # Eliminar todos los índices existentes\n",
    "      self.nodes.drop_indexes()\n",
    "      self.edges.drop_indexes()\n",
    "      \n",
    "      # Recrear los índices\n",
    "      self._create_indexes()\n",
    "      \n",
    "      return {\n",
    "        \"success\": True,\n",
    "        \"message\": \"Base de datos reiniciada exitosamente\",\n",
    "        \"nodes_deleted\": clear_result[\"nodes_deleted\"],\n",
    "        \"edges_deleted\": clear_result[\"edges_deleted\"],\n",
    "        \"indexes_recreated\": True,\n",
    "        \"database_reset\": True\n",
    "      }\n",
    "    except Exception as e:\n",
    "      return {\n",
    "        \"success\": False,\n",
    "        \"message\": f\"Error al reiniciar la base de datos: {str(e)}\",\n",
    "        \"nodes_deleted\": 0,\n",
    "        \"edges_deleted\": 0,\n",
    "        \"indexes_recreated\": False\n",
    "      }\n",
    "  \n",
    "  def close_connection(self) -> None:\n",
    "    \"Cierra la conexión a MongoDB\"\n",
    "    self.client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdcc8cc",
   "metadata": {},
   "source": [
    "### Init GraphDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f5cb955",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_db = GraphDB('graph_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25fc8b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"success\": true,\n",
      "  \"message\": \"Base de datos reiniciada exitosamente\",\n",
      "  \"nodes_deleted\": 9,\n",
      "  \"edges_deleted\": 8,\n",
      "  \"indexes_recreated\": true,\n",
      "  \"database_reset\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "reset_result = graph_db.reset_database(confirm=True)\n",
    "print(json.dumps(reset_result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f297c3",
   "metadata": {},
   "source": [
    "### Add Nodes (Entities) / Add Edges (Relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b83108a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True,\n",
       " 'message': 'Arista creada exitosamente: polynomials -> vector_spaces (form)',\n",
       " 'edge_created': True,\n",
       " 'duplicate_found': False,\n",
       " 'edge_id': '6872b2eba12e36523b3ee204',\n",
       " 'edges_created': 1,\n",
       " 'reverse_created': False}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nodos de álgebra\n",
    "graph_db.add_node(\"linear_equations\", \"algebra\", {\"name\": \"Linear Equations\", \"description\": \"Equations of the first degree\"})\n",
    "graph_db.add_node(\"quadratic_equations\", \"algebra\", {\"name\": \"Quadratic Equations\", \"description\": \"Equations of the second degree\"})\n",
    "graph_db.add_node(\"polynomials\", \"algebra\", {\"name\": \"Polynomials\", \"description\": \"Expressions involving variables and coefficients\"})\n",
    "graph_db.add_node(\"matrices\", \"algebra\", {\"name\": \"Matrices\", \"description\": \"Rectangular arrays of numbers\"})\n",
    "graph_db.add_node(\"vector_spaces\", \"algebra\", {\"name\": \"Vector Spaces\", \"description\": \"Collections of vectors\"})\n",
    "\n",
    "# Nodos de análisis\n",
    "graph_db.add_node(\"limits\", \"analysis\", {\"name\": \"Limits\", \"description\": \"Behavior of functions as inputs approach a value\"})\n",
    "graph_db.add_node(\"derivatives\", \"analysis\", {\"name\": \"Derivatives\", \"description\": \"Rates of change of functions\"})\n",
    "graph_db.add_node(\"integrals\", \"analysis\", {\"name\": \"Integrals\", \"description\": \"Area under curves\"})\n",
    "graph_db.add_node(\"sequences\", \"analysis\", {\"name\": \"Sequences\", \"description\": \"Ordered lists of numbers\"})\n",
    "graph_db.add_node(\"series\", \"analysis\", {\"name\": \"Series\", \"description\": \"Sum of sequences\"})\n",
    "\n",
    "# Relaciones entre contenidos\n",
    "graph_db.add_edge(\"linear_equations\", \"matrices\", \"solved_by\", {\"method\": \"Gaussian elimination\"}, True)\n",
    "graph_db.add_edge(\"quadratic_equations\", \"polynomials\", \"is_a_case_of\", {}, True)\n",
    "graph_db.add_edge(\"polynomials\", \"limits\", \"analyzed_with\", {}, True)\n",
    "graph_db.add_edge(\"limits\", \"derivatives\", \"foundation_for\", {}, True)\n",
    "graph_db.add_edge(\"derivatives\", \"integrals\", \"inverse_of\", {}, True)\n",
    "graph_db.add_edge(\"sequences\", \"series\", \"forms\", {}, True)\n",
    "graph_db.add_edge(\"series\", \"limits\", \"converges_to\", {}, True)\n",
    "graph_db.add_edge(\"vector_spaces\", \"matrices\", \"represented_by\", {}, True)\n",
    "graph_db.add_edge(\"matrices\", \"vector_spaces\", \"act_on\", {}, True)\n",
    "graph_db.add_edge(\"polynomials\", \"vector_spaces\", \"form\", {\"type\": \"polynomial vector space\"}, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33a89b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Adjacent Entities ===\n",
      "Entity: matrices (algebra)\n",
      "Relationship: solved_by (outgoing)\n",
      "Properties: {'name': 'Matrices', 'description': 'Rectangular arrays of numbers'}\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "adjacent = graph_db.get_adjacent_entities(\"linear_equations\")\n",
    "print(\"=== Adjacent Entities ===\")\n",
    "for entity in adjacent:\n",
    "  print(f\"Entity: {entity['node_id']} ({entity['type']})\")\n",
    "  print(f\"Relationship: {entity['relationship']['type']} ({entity['relationship']['direction']})\")\n",
    "  print(f\"Properties: {entity['properties']}\")\n",
    "  print(\"-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "674416bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_equations: solved_by\n"
     ]
    }
   ],
   "source": [
    "work_relations = graph_db.get_adjacent_entities(\"matrices\", relation_filter=\"solved_by\")\n",
    "for entity in work_relations:\n",
    "  print(f\"{entity['node_id']}: {entity['relationship']['type']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3eb53a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Graph Stats ===\n",
      "{\n",
      "  \"total_nodes\": 10,\n",
      "  \"total_edges\": 10,\n",
      "  \"node_types\": [\n",
      "    \"algebra\",\n",
      "    \"analysis\"\n",
      "  ],\n",
      "  \"relationship_types\": [\n",
      "    \"act_on\",\n",
      "    \"analyzed_with\",\n",
      "    \"converges_to\",\n",
      "    \"form\",\n",
      "    \"forms\",\n",
      "    \"foundation_for\",\n",
      "    \"inverse_of\",\n",
      "    \"is_a_case_of\",\n",
      "    \"represented_by\",\n",
      "    \"solved_by\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Graph Stats ===\")\n",
    "print(json.dumps(graph_db.get_graph_stats(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8088d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"success\": true,\n",
      "  \"message\": \"Node series eliminado con exito\",\n",
      "  \"nodes_deleted\": 1,\n",
      "  \"edges_deleted\": 2,\n",
      "  \"existing_edges\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "delete_result = graph_db.del_node(\"series\")\n",
    "print(json.dumps(delete_result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd5118a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# always remember: close connection\n",
    "graph_db.close_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c96594",
   "metadata": {},
   "source": [
    "### Entity Relationship Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cbffac",
   "metadata": {},
   "source": [
    "#### Auxiliar Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e15bec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_paths_between_entities(self:GraphDB,\n",
    "      source:str,\n",
    "      target:str,\n",
    "      max_depth:int,\n",
    "      max_paths:int ) -> Dict:\n",
    "  \"\"\"Encuentra todos los caminos posibles entre dos entidades usando BFS con múltiples caminos \n",
    "\n",
    "  Args:\n",
    "      source (str): entidad origen\n",
    "      target (str): entidad destino\n",
    "      max_depth (int): profundidad máxima de búsqueda\n",
    "      max_paths (int): número máximo de caminos a retornar\n",
    "\n",
    "  Returns:\n",
    "      Dict: información sobre los caminos encontrados\n",
    "  \"\"\"\n",
    "  # validar que ambas entidades existen\n",
    "  if not self._node_exists(target):\n",
    "    return {\n",
    "      \"success\": False,\n",
    "      \"message\": f\"La entidad '{target}' no existe en el grafo\",\n",
    "      \"query_type\": \"path_finding\"\n",
    "    }\n",
    "  \n",
    "  # verificar si ya existe una relación directa \n",
    "  direct_relations = self.get_adjacent_entities(source)\n",
    "  direct_target = next( (rel for rel in direct_relations if rel[\"node_id\"] == target), None )\n",
    "  \n",
    "  if direct_target:\n",
    "    return {\n",
    "      \"success\": True,\n",
    "      \"query_type\": \"direct_relation\",\n",
    "      \"source\": source,\n",
    "      \"target\": target,\n",
    "      \"direct_relation\": direct_target,\n",
    "      \"message\": f\"Existe una relación directa entre `{source}` y `target`\"\n",
    "    }\n",
    "  \n",
    "  # BFS para encontrar múltiples caminos\n",
    "  paths_found = []\n",
    "  queue = deque([(source, [source], 0)])  # nodo_actual, camino, profundidad\n",
    "  visited_paths = set()                   # para evitar caminos duplicados\n",
    "  \n",
    "  while queue and len(paths_found) < max_paths:\n",
    "    current_node, path, depth = queue.popleft()\n",
    "    if depth >= max_depth: continue\n",
    "    \n",
    "    # obtener entidades adyacentes\n",
    "    adjacent = self.get_adjacent_entities(current_node)\n",
    "    \n",
    "    for adj_entity in adjacent:\n",
    "      next_node = adj_entity[\"node_id\"]\n",
    "      \n",
    "      # si encontramos el objetivo\n",
    "      if next_node == target:\n",
    "        complete_path = path + [next_node]\n",
    "        path_key = \"->\".join(complete_path)\n",
    "        \n",
    "        if path_key not in visited_paths:\n",
    "          visited_paths.add(path_key)\n",
    "\n",
    "          # construir información detallada del camino\n",
    "          path_details = self._build_path_details(complete_path)\n",
    "          \n",
    "          paths_found.append({\n",
    "            \"path\": complete_path,\n",
    "            \"length\": len(complete_path) - 1,\n",
    "            \"details\": path_details\n",
    "          })\n",
    "      \n",
    "      # si no se ha visitado este nodo en este camino, continuar explorando\n",
    "      elif next_node not in path:\n",
    "        new_path = path + [next_node]\n",
    "        queue.append((next_node,new_path,depth + 1))\n",
    "    \n",
    "  # ordenar caminos por longitud \n",
    "  paths_found.sort(key=lambda x:x[\"length\"])\n",
    "  \n",
    "  return {\n",
    "    \"success\": True,\n",
    "    \"query_type\": \"path_finding\",\n",
    "    \"source\": source,\n",
    "    \"target\": target,\n",
    "    \"paths_found\": len(paths_found),\n",
    "    \"paths\": paths_found[:max_paths],\n",
    "    \"message\": f\"Se encontraron {len(paths_found)} caminos entre `{source}` y `{target}`\"\n",
    "  }\n",
    "\n",
    "def _calculate_relation_probabilities(self:GraphDB,\n",
    "      entity:str,\n",
    "      relation_type:str,\n",
    "      max_depth:int ) -> Dict:\n",
    "  \"\"\"Calcula la probabilidad de que una entidad tenga una relación específica con otras entidades basándose en caminos indirectos y patrones en el grafo\n",
    "\n",
    "  Args:\n",
    "      entity (str): entidad base\n",
    "      relation_type (str): tipo de relación a analizar\n",
    "      max_depth (int): profundidad máxima para análisis\n",
    "\n",
    "  Returns:\n",
    "      Dict: Probabilidades calculadas para cada entidad\n",
    "  \"\"\"\n",
    "  \n",
    "  # verificar si el tipo de relación existe en el grafo\n",
    "  existing_relations = self.get_relationship_types()\n",
    "  if relation_type not in existing_relations:\n",
    "    return {\n",
    "      \"success\": False,\n",
    "      \"message\": f\"El tipo de relación `{relation_type}` no existe en el grafo\",\n",
    "      \"available_relations\": existing_relations,\n",
    "      \"query_type\": \"relation_probability\"\n",
    "    }\n",
    "  \n",
    "  # obtener todas las relaciones directas de la entidad \n",
    "  direct_relations = self.get_adjacent_entities(entity)\n",
    "  direct_relation_targets = {rel[\"node_id\"] for rel in direct_relations if rel[\"relationship\"][\"type\"] == relation_type}\n",
    "  \n",
    "  # obtener todos los nodos del grafo\n",
    "  all_nodes = list(self.nodes.find({}, {\"node_id\": 1, \"type\": 1}))\n",
    "  \n",
    "  # calcular probabilidades para cada nodo\n",
    "  probabilities = []\n",
    "  \n",
    "  for node_doc in all_nodes:\n",
    "    target_node = node_doc[\"node_id\"]\n",
    "    if target_node == entity: continue\n",
    "    \n",
    "    # si ya existe una relación directa, entonces probabilidad = 1.0\n",
    "    if target_node in direct_relation_targets:\n",
    "      probabilities.append({\n",
    "        \"node_id\": target_node,\n",
    "        \"node_type\": node_doc[\"type\"],\n",
    "        \"probability\": 1.0,\n",
    "        \"message\": \"Relación directa encontrada\",\n",
    "        \"evidence\": []\n",
    "      })\n",
    "      continue\n",
    "    \n",
    "    # calcular probabilidad basada en algunos factores \n",
    "    probability, evidence = self._calculate_indirect_probability(entity, target_node, relation_type, max_depth)\n",
    "    if probability > 0:\n",
    "      probabilities.append({\n",
    "        \"node_id\": target_node,\n",
    "        \"node_type\": node_doc[\"type\"],\n",
    "        \"probability\": probability,\n",
    "        \"message\": \"Relación indirecta encontrada basada en patrones indirectos\",\n",
    "        \"evidence\": evidence\n",
    "      })\n",
    "  \n",
    "  # ordenar por probabilidad (mayor primero)\n",
    "  probabilities.sort(key=lambda x:x[\"probability\"], reverse=True)\n",
    "  \n",
    "  return {\n",
    "    \"success\": True,\n",
    "    \"query_type\": \"relation_probability\",\n",
    "    \"entity\": entity,\n",
    "    \"relation_type\": relation_type,\n",
    "    \"total_candidates\": len(probabilities),\n",
    "    \"direct_relations\": len(direct_relation_targets),\n",
    "    \"probabilities\": probabilities,  \n",
    "    \"message\": f\"Calculadas probabilidades de relación '{relation_type}' para '{entity}'\"\n",
    "  }\n",
    "\n",
    "def _calculate_indirect_probability(self:GraphDB,\n",
    "      source:str,\n",
    "      target:str,\n",
    "      relation_type:str,\n",
    "      max_depth:int ) -> Tuple[float, List[Dict]]:\n",
    "  \"\"\"Calcula la probabilidad indirecta de relación basada en:\n",
    "  1. Entidades comunes conectadas con el mismo tipo de relación\n",
    "  2. Caminos cortos entre las entidades\n",
    "\n",
    "  Args:\n",
    "      source (str): entidad origen\n",
    "      target (str): entidad objetivo\n",
    "      relation_type (str): tipo de relación\n",
    "      max_depth (int): profundidad máxima\n",
    "\n",
    "  Returns:\n",
    "      Tuple[float, List[Dict]]: probabilidad y evidencia\n",
    "  \"\"\"\n",
    "  evidence = []\n",
    "  probability_factors = []\n",
    "  \n",
    "  # factor 1: entidades comunes conectadas con el mismo tipo de relación\n",
    "  source_relations = self.get_adjacent_entities(source, relation_filter=relation_type)\n",
    "  target_relations = self.get_adjacent_entities(target, relation_filter=relation_type)\n",
    "  \n",
    "  source_connected = {rel[\"node_id\"] for rel in source_relations}\n",
    "  target_connected = {rel[\"node_id\"] for rel in target_relations}\n",
    "  \n",
    "  common_entities = source_connected.intersection(target_connected)\n",
    "  \n",
    "  if common_entities:\n",
    "    # m: entidades conectadas a source\n",
    "    m = len(source_connected)\n",
    "    # n: entidades conectadas a target\n",
    "    n = len(target_connected)\n",
    "    # p: entidades comunes entre source y target\n",
    "    p = len(common_entities)\n",
    "    \n",
    "    # máximo de conexiones comunes posibles \n",
    "    common_max = min(m,n)\n",
    "    \n",
    "    common_factor = 0.0 # evitar división por cero\n",
    "    if common_max != 0: common_factor = min(p/common_max, 1.0) # P(A) = conexiones-reales / máximo-posible\n",
    "    \n",
    "    probability_factors.append(common_factor)\n",
    "    evidence.append({\n",
    "      \"type\": \"common_entities\",\n",
    "      \"count\": len(common_entities),\n",
    "      \"entities\": list(common_entities),\n",
    "      \"contribution\": common_factor\n",
    "    })\n",
    "  \n",
    "  # factor 2: caminos cortos entre entidades => P(B) = 1/d(i,j)\n",
    "  paths_result = self._find_paths_between_entities(source,target,min(max_depth, 3), 5)\n",
    "  if paths_result[\"success\"] and \"paths\" in paths_result:\n",
    "    shortest_path_length = min(path[\"length\"] for path in paths_result[\"paths\"]) if paths_result[\"paths\"] else float('inf')\n",
    "    if shortest_path_length != float('inf'): \n",
    "      path_factor = 1/shortest_path_length\n",
    "      \n",
    "      probability_factors.append(path_factor)\n",
    "      evidence.append({\n",
    "        \"type\": \"shortest_path\", \n",
    "        \"shortest_length\": shortest_path_length,\n",
    "        \"total_paths\": len(paths_result[\"paths\"]),\n",
    "        \"contribution\": path_factor\n",
    "      })\n",
    "  \n",
    "  # unión de probabilidades independientes: P(A u B) = P(A) + P(B) - P(A)*P(B)\n",
    "  if probability_factors:\n",
    "    combined_probability = probability_factors[0]\n",
    "    for factor in probability_factors[1:]:\n",
    "      combined_probability = combined_probability + factor - (combined_probability * factor)\n",
    "    return combined_probability, evidence\n",
    "  \n",
    "  return 0.0, evidence\n",
    "\n",
    "def _build_path_details(self:GraphDB, path:List[str]) -> List[Dict]:\n",
    "  \"\"\"Construye información detallada para un camino específico\n",
    "\n",
    "  Args:\n",
    "      path (List[str]): lista de nodos en el camino\n",
    "\n",
    "  Returns:\n",
    "      List[Dict]: detalles de cada paso en el camino\n",
    "  \"\"\"\n",
    "  details = []\n",
    "  for i in range(len(path) - 1):\n",
    "    current_node = path[i]\n",
    "    next_node = path[i+1]\n",
    "\n",
    "    # encontrar la relación entre estos dos nodos\n",
    "    current_adjacent = self.get_adjacent_entities(current_node)\n",
    "    relation_info = next((rel for rel in current_adjacent if rel[\"node_id\"] == next_node), None)\n",
    "\n",
    "    if relation_info:\n",
    "      details.append({\n",
    "        \"from\": current_node,\n",
    "        \"to\": next_node,\n",
    "        \"relation_type\": relation_info[\"relationship\"][\"type\"],\n",
    "        \"direction\": relation_info[\"relationship\"][\"direction\"],\n",
    "        \"properties\": relation_info[\"relationship\"][\"properties\"]\n",
    "      })\n",
    "  \n",
    "  return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dd97e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GraphDB._find_paths_between_entities = _find_paths_between_entities\n",
    "GraphDB._calculate_relation_probabilities = _calculate_relation_probabilities\n",
    "GraphDB._calculate_indirect_probability = _calculate_indirect_probability\n",
    "GraphDB._build_path_details = _build_path_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93798f08",
   "metadata": {},
   "source": [
    "#### Retriever Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2af9f0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73b764f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriever(self:GraphDB, \n",
    "      query_entity_1:str, \n",
    "      query_entity_2:str = None,\n",
    "      relation_type:str = None,\n",
    "      max_depth:int = 4, \n",
    "      max_paths:int = 10 ) -> Dict:\n",
    "  \"\"\"Recuperador avanzado para el grafo que maneja dos casos principales:\n",
    "  1. Encontrar caminos entre dos entidades no adyacentes\n",
    "  2. Calcular probabilidades de la relación entre una entidad y todas las demás para un tipo de relación específico\n",
    "\n",
    "  Args:\n",
    "      query_entity_1 (str): primera entidad (siempre requerida)\n",
    "      query_entity_2 (str, optional): segunda entidad para encontrar caminos. Defaults to None.\n",
    "      relation_type (str, optional): tipo de relación para calcular probabilidades. Defaults to None.\n",
    "      max_depth (int, optional): profundidad máxima de búsqueda. Defaults to 4.\n",
    "      max_paths (int, optional): número máximo de caminos a retornar. Defaults to 10.\n",
    "\n",
    "  Returns:\n",
    "      Dict: Resultado con caminos encontrados o probabilidades calculadas\n",
    "  \"\"\"\n",
    "  # validar que la primera entidad existe\n",
    "  if not self._node_exists(query_entity_1):\n",
    "    return {\n",
    "      \"success\": False,\n",
    "      \"message\": f\"La entidad '{query_entity_1}' no existe en el grafo\",\n",
    "      \"query_type\": \"error\"\n",
    "    }\n",
    "  \n",
    "  # caso 1: encontrar caminos entre dos entidades específicas\n",
    "  if query_entity_2 is not None:\n",
    "    return self._find_paths_between_entities(query_entity_1,query_entity_2,max_depth,max_paths)\n",
    "  \n",
    "  # caso 2: calcular probabilidades de relación para un tipo específico \n",
    "  elif relation_type is not None:\n",
    "    return self._calculate_relation_probabilities(query_entity_1, relation_type, max_depth)\n",
    "  \n",
    "  # error: parámetros insuficientes\n",
    "  else:\n",
    "    return {\n",
    "      \"success\": False,\n",
    "      \"message\": \"Debe proporcionar `query_entity_2` (para encontrar caminos) o `relation_type` (para calcular probabilidades)\",\n",
    "      \"query_type\": \"error\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d11dd88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GraphDB.retriever = retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3277f6a0",
   "metadata": {},
   "source": [
    "#### Subgraph Extraction Function\n",
    "\n",
    "La siguiente función permite: \n",
    "- Buscar todas las aristas de un tipo de relación especificado\n",
    "- Identificar los nodos involucrados en esas relaciones \n",
    "- Extrae la información de esos nodos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e9d3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subgraph_by_relation(self:GraphDB, relation_type:str) -> Dict:\n",
    "  \"\"\"Extrae un subgrafo formado por todas las relaciones de un tipo específico \n",
    "  y los nodos que participan en dichas relaciones. \n",
    "\n",
    "  Args:\n",
    "    relation_type (str): tipo de relación para filtrar el subgrafo\n",
    "\n",
    "  Returns:\n",
    "    Dict: Diccionario con la información del subgrafo que contiene:\n",
    "    - `success`: bool indicando si la operación fue exitosa\n",
    "    - `message`: str con mensaje descriptivo\n",
    "    - `nodes`: List[Dict] con información de los nodos del subgrafo\n",
    "    - `edges`: List[Dict] con información de las aristas del subgrafo\n",
    "    - `stats`: Dict con estadísticas del subgrafo\n",
    "  \"\"\"\n",
    "  try:\n",
    "    # buscar todas las aristas del tipo de relación especificado\n",
    "    edges_cursor = self.edges.find({\"relation_type\": relation_type})\n",
    "    subgraph_edges = []\n",
    "    involved_node_ids = set()\n",
    "    \n",
    "    # procesar cada arista encontrada\n",
    "    for edge in edges_cursor:\n",
    "      involved_node_ids.add(edge['source'])\n",
    "      involved_node_ids.add(edge['target'])\n",
    "      \n",
    "      edge_info = {\n",
    "        \"source\": edge[\"source\"],\n",
    "        \"target\": edge['target'],\n",
    "        \"relation_type\": edge[\"relation_type\"],\n",
    "        \"properties\": edge[\"properties\"],\n",
    "        \"directed\": edge[\"directed\"]\n",
    "      }\n",
    "      subgraph_edges.append(edge_info)\n",
    "    \n",
    "    # si no se encontraron aristas del tipo específico \n",
    "    if not subgraph_edges:\n",
    "      return {\n",
    "        \"success\": True,\n",
    "        \"message\": f\"No se encontraron relaciones del tipo: {relation_type}\",\n",
    "        \"nodes\": [],\n",
    "        \"edges\": [],\n",
    "        \"stats\": {\n",
    "          \"total_nodes\": 0,\n",
    "          \"total_edges\": 0,\n",
    "          \"relation_type\": relation_type\n",
    "        }\n",
    "      }\n",
    "    \n",
    "    # obtener información de todos los nodos involucrados\n",
    "    subgraph_nodes = []\n",
    "    nodes_cursor = self.nodes.find({\"node_id\": {\"$in\": list(involved_node_ids)}})\n",
    "    \n",
    "    for node in nodes_cursor: \n",
    "      node_info = {\n",
    "        \"node_id\": node[\"node_id\"],\n",
    "        \"type\": node[\"type\"],\n",
    "        \"properties\": node[\"properties\"]\n",
    "      }\n",
    "      subgraph_nodes.append(node_info)\n",
    "    \n",
    "    # generar estadísticas del subgrafo\n",
    "    node_types = list(set(node[\"type\"] for node in subgraph_nodes))\n",
    "    \n",
    "    stats = {\n",
    "      \"total_nodes\": len(subgraph_nodes),\n",
    "      \"total_edges\": len(subgraph_edges),\n",
    "      \"relation_type\": relation_type,\n",
    "      \"node_types_in_subgraph\": node_types,\n",
    "      \"unique_nodes\": len(involved_node_ids),\n",
    "      \"directed_edges\": sum(1 for edge in subgraph_edges if edge[\"directed\"]),\n",
    "      \"undirected_edges\": sum(1 for edge in subgraph_edges if not edge[\"directed\"])\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "      \"success\": True,\n",
    "      \"message\": f\"Subgrafo extraído exitosamente para relación: {relation_type}\",\n",
    "      \"nodes\": subgraph_nodes,\n",
    "      \"edges\": subgraph_edges,\n",
    "      \"stats\": stats \n",
    "    }\n",
    "  except Exception as e:\n",
    "    return {\n",
    "      \"success\": False,\n",
    "      \"message\": f\"Error al extraer subgrafo: {str(e)}\",\n",
    "      \"nodes\": [],\n",
    "      \"edges\": [],\n",
    "      \"stats\": {\n",
    "        \"total_nodes\": 0,\n",
    "        \"total_edges\": 0,\n",
    "        \"relation_type\": relation_type\n",
    "      }\n",
    "    }\n",
    "\n",
    "GraphDB.extract_subgraph_by_relation = extract_subgraph_by_relation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafc75d0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96e6598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_dag(self:GraphDB) -> Dict:\n",
    "  \"\"\"Verifica si el grafo es un DAG (Directed Acyclic Graph)\n",
    "\n",
    "  Un grafo es DAG si: \n",
    "  1. Todas las aristas son dirigidas\n",
    "  2. No contiene ciclos\n",
    "\n",
    "  Utiliza el algoritmo de Kahn (orden topológico) para detectar ciclos\n",
    "\n",
    "  Returns:\n",
    "    Dict: resultado de la verificación:\n",
    "      - `is_dag`: bool indicando si es DAG\n",
    "      - `message`: str con mensaje descriptivo\n",
    "      - `has_undirected_edges`: bool si tiene aristas no dirigidas\n",
    "      - `has_cycles`: bool si tiene ciclos\n",
    "      - `cycle_info`: Dict con información del ciclo encontrado (si existe)\n",
    "      - `stats`: Dict con estadísticas del análisis\n",
    "  \"\"\"\n",
    "  try:\n",
    "    # obtener todas las aristas\n",
    "    edges_cursor = self.edges.find({})\n",
    "    edges_list = list(edges_cursor)\n",
    "    \n",
    "    # verificar si hay aristas no dirigdas\n",
    "    undirected_edges = [edge for edge in edges_list if not edge.get(\"directed\", True)]\n",
    "    has_undirected = len(undirected_edges) > 0\n",
    "    \n",
    "    if has_undirected:\n",
    "      return {\n",
    "        \"is_dag\": False,\n",
    "        \"message\": f\"El grafo NO es DAG: contiene {len(undirected_edges)} aristas no dirigidas\",\n",
    "        \"has_undirected_edges\": True,\n",
    "        \"has_cycles\": None,   # no se puede determinar sin verificar ciclos\n",
    "        \"cycle_info\": None,\n",
    "        \"stats\": {\n",
    "          \"total_edges\": len(edges_list),\n",
    "          \"directed_edges\": len(edges_list) - len(undirected_edges),\n",
    "          \"undirected_edges\": len(undirected_edges),\n",
    "          \"total_nodes\": self.nodes.count_documents({})\n",
    "        }\n",
    "      }\n",
    "      \n",
    "    # solo considerar aristas dirigidas para el análisis de ciclos\n",
    "    directed_edges = [edge for edge in edges_list if edge.get(\"directed\", True)]\n",
    "    cycle_result = detect_cycles_kahn(self, directed_edges)\n",
    "    \n",
    "    if cycle_result[\"has_cycles\"]:\n",
    "      return {\n",
    "        \"is_dag\": False, \n",
    "        \"message\": f\"El grafo NO es DAG: se detectaron ciclos\",\n",
    "        \"has_undirected_edges\": False,\n",
    "        \"has_cycles\": True,\n",
    "        \"cycle_info\": cycle_result[\"cycle_info\"],\n",
    "        \"stats\": {\n",
    "          \"total_edges\": len(edges_list),\n",
    "          \"directed_edges\": len(directed_edges),\n",
    "          \"undirected_edges\": len(undirected_edges),\n",
    "          \"total_nodes\": self.nodes.count_documents({}),\n",
    "          \"nodes_in_cycles\": len(cycle_result[\"cycle_info\"][\"remaining_nodes\"])\n",
    "        }\n",
    "      }\n",
    "    return {\n",
    "      \"is_dag\": True,\n",
    "      \"message\": \"El grafo es DAG: todas las aristas son dirigidas y no hay ciclos\",\n",
    "      \"has_undirected_edges\": False,\n",
    "      \"has_cycles\": False,\n",
    "      \"cycle_info\": None,\n",
    "      \"stats\": {\n",
    "        \"total_edges\": len(edges_list),\n",
    "        \"directed_edges\": len(directed_edges),\n",
    "        \"undirected_edges\": len(undirected_edges),\n",
    "        \"total_nodes\": self.nodes.count_documents({}),\n",
    "        \"topological_order\": cycle_result[\"topological_order\"]\n",
    "      }\n",
    "    }\n",
    "  except Exception as e:\n",
    "    return {\n",
    "      \"is_dag\": False,\n",
    "      \"message\": f\"Error al verificar DAG: {str(e)}\",\n",
    "      \"has_undirected_edges\": None,\n",
    "      \"has_cycles\": None,\n",
    "      \"stats\": {}\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def detect_cycles_kahn(self:GraphDB, directed_edges:List) -> Dict:\n",
    "  \"\"\"Detecta ciclos usando el algoritmo de Kahn (orden topológico)\n",
    "  \n",
    "  Args:\n",
    "    directed_edges (List): lista de aristas dirigidas\n",
    "\n",
    "  Returns:\n",
    "    Dict: resultado de análisis de ciclos\n",
    "  \"\"\"\n",
    "  try: \n",
    "    # Construir grafo de adyacencia y contar grados de entrada\n",
    "    graph = {}\n",
    "    in_degree = {}\n",
    "    all_nodes = set()\n",
    "    \n",
    "    # Inicializar estructuras\n",
    "    for edge in directed_edges:\n",
    "      source = edge[\"source\"]\n",
    "      target = edge[\"target\"]\n",
    "      all_nodes.add(source)\n",
    "      all_nodes.add(target)\n",
    "      \n",
    "      if source not in graph:\n",
    "        graph[source] = []\n",
    "      if target not in graph:\n",
    "        graph[target] = []\n",
    "      if source not in in_degree:\n",
    "        in_degree[source] = 0\n",
    "      if target not in in_degree:\n",
    "        in_degree[target] = 0\n",
    "    \n",
    "    # Construir lista de adyacencia y contar grados de entrada\n",
    "    for edge in directed_edges:\n",
    "            source = edge[\"source\"]\n",
    "            target = edge[\"target\"]\n",
    "            graph[source].append(target)\n",
    "            in_degree[target] += 1\n",
    "    \n",
    "    # Encontrar nodos con grado de entrada 0\n",
    "    queue = [node for node in all_nodes if in_degree[node] == 0]\n",
    "    topological_order = []\n",
    "    \n",
    "    while queue:\n",
    "      current = queue.pop(0)\n",
    "      topological_order.append(current)\n",
    "      \n",
    "      # Reducir grado de entrada de nodos adyacentes\n",
    "      for neighbor in graph[current]:\n",
    "        in_degree[neighbor] -= 1\n",
    "        if in_degree[neighbor] == 0:\n",
    "          queue.append(neighbor)\n",
    "    \n",
    "    # Si no todos los nodos están en el orden topológico, hay ciclos\n",
    "    if len(topological_order) != len(all_nodes):\n",
    "      remaining_nodes = [node for node in all_nodes if node not in topological_order]\n",
    "      \n",
    "      # Encontrar un ciclo específico\n",
    "      cycle_path = self._find_cycle_path(graph, remaining_nodes)\n",
    "      \n",
    "      return {\n",
    "        \"has_cycles\": True,\n",
    "        \"cycle_info\": {\n",
    "          \"remaining_nodes\": remaining_nodes,\n",
    "          \"nodes_in_cycles\": len(remaining_nodes),\n",
    "          \"example_cycle\": cycle_path\n",
    "        },\n",
    "        \"topological_order\": topological_order\n",
    "      }\n",
    "    else:\n",
    "      return {\n",
    "        \"has_cycles\": False,\n",
    "        \"cycle_info\": None,\n",
    "        \"topological_order\": topological_order\n",
    "      }\n",
    "  except Exception as e:\n",
    "    return {\n",
    "      \"has_cycles\": None,\n",
    "      \"cycle_info\": {\"error\": str(e)},\n",
    "      \"topological_order\": []\n",
    "    }\n",
    "\n",
    "GraphDB.detect_cycles_kahn = detect_cycles_kahn\n",
    "GraphDB.is_dag = is_dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5dcb48c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"discrete_math\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"discrete_math\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'discrete_math'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"linear_algebra\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"linear_algebra\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'linear_algebra'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"calculus\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"calculus\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'calculus'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"statistics\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"statistics\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'statistics'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"programming_basics\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"programming_basics\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'programming_basics'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"data_structures\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"data_structures\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'data_structures'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"algorithms\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"algorithms\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'algorithms'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"object_oriented_programming\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"object_oriented_programming\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'object_oriented_programming'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"discrete_math\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"discrete_math\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'discrete_math'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"algorithms\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"algorithms\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'algorithms'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"computer_logic\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"computer_logic\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'computer_logic'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"graph_theory\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"graph_theory\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'graph_theory'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"linear_algebra\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"linear_algebra\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'linear_algebra'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"machine_learning\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"machine_learning\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'machine_learning'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"calculus\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"calculus\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'calculus'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"numerical_methods\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"numerical_methods\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'numerical_methods'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"optimization\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"optimization\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'optimization'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"machine_learning\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"machine_learning\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'machine_learning'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"statistics\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"statistics\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'statistics'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"data_science\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"data_science\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'data_science'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"machine_learning\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"machine_learning\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'machine_learning'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"artificial_intelligence\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"artificial_intelligence\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'artificial_intelligence'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"data_structures\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"data_structures\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'data_structures'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"algorithms\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"algorithms\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'algorithms'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"advanced_algorithms\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"advanced_algorithms\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'advanced_algorithms'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"object_oriented_programming\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"object_oriented_programming\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'object_oriented_programming'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"computer_logic\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"computer_logic\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'computer_logic'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"formal_methods\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"formal_methods\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'formal_methods'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"automated_reasoning\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"automated_reasoning\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'automated_reasoning'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"graph_theory\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"graph_theory\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'graph_theory'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"artificial_intelligence\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"artificial_intelligence\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'artificial_intelligence'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"expert_systems\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"expert_systems\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'expert_systems'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"machine_learning\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"machine_learning\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'machine_learning'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"deep_learning\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"deep_learning\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'deep_learning'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"reinforcement_learning\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"reinforcement_learning\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'reinforcement_learning'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"neural_networks\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"neural_networks\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'neural_networks'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"deep_learning\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"deep_learning\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'deep_learning'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"computer_vision\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"computer_vision\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'computer_vision'}}\n",
      "Error al insertar nodo: E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"natural_language_processing\" }, full error: {'index': 0, 'code': 11000, 'errmsg': 'E11000 duplicate key error collection: prerequisites_graph.nodes index: node_id_1 dup key: { node_id: \"natural_language_processing\" }', 'keyPattern': {'node_id': 1}, 'keyValue': {'node_id': 'natural_language_processing'}}\n",
      "OK: basic_math -> discrete_math : Arista creada exitosamente: basic_math -> discrete_math (prerequisito)\n",
      "OK: basic_math -> linear_algebra : Arista creada exitosamente: basic_math -> linear_algebra (prerequisito)\n",
      "OK: basic_math -> calculus : Arista creada exitosamente: basic_math -> calculus (prerequisito)\n",
      "OK: basic_math -> statistics : Arista creada exitosamente: basic_math -> statistics (prerequisito)\n",
      "OK: programming_basics -> data_structures : Arista creada exitosamente: programming_basics -> data_structures (prerequisito)\n",
      "OK: programming_basics -> algorithms : Arista creada exitosamente: programming_basics -> algorithms (prerequisito)\n",
      "OK: programming_basics -> object_oriented_programming : Arista creada exitosamente: programming_basics -> object_oriented_programming (prerequisito)\n",
      "OK: discrete_math -> algorithms : Arista creada exitosamente: discrete_math -> algorithms (prerequisito)\n",
      "OK: discrete_math -> computer_logic : Arista creada exitosamente: discrete_math -> computer_logic (prerequisito)\n",
      "OK: discrete_math -> cryptography : Arista creada exitosamente: discrete_math -> cryptography (prerequisito)\n",
      "OK: discrete_math -> graph_theory : Arista creada exitosamente: discrete_math -> graph_theory (prerequisito)\n",
      "OK: linear_algebra -> machine_learning : Arista creada exitosamente: linear_algebra -> machine_learning (prerequisito)\n",
      "OK: linear_algebra -> computer_graphics : Arista creada exitosamente: linear_algebra -> computer_graphics (prerequisito)\n",
      "OK: linear_algebra -> data_science : Arista creada exitosamente: linear_algebra -> data_science (prerequisito)\n",
      "OK: calculus -> numerical_methods : Arista creada exitosamente: calculus -> numerical_methods (prerequisito)\n",
      "OK: calculus -> optimization : Arista creada exitosamente: calculus -> optimization (prerequisito)\n",
      "OK: calculus -> machine_learning : Arista creada exitosamente: calculus -> machine_learning (prerequisito)\n",
      "OK: statistics -> data_science : Arista creada exitosamente: statistics -> data_science (prerequisito)\n",
      "OK: statistics -> machine_learning : Arista creada exitosamente: statistics -> machine_learning (prerequisito)\n",
      "OK: statistics -> artificial_intelligence : Arista creada exitosamente: statistics -> artificial_intelligence (prerequisito)\n",
      "OK: data_structures -> advanced_algorithms : Arista creada exitosamente: data_structures -> advanced_algorithms (prerequisito)\n",
      "OK: data_structures -> database_design : Arista creada exitosamente: data_structures -> database_design (prerequisito)\n",
      "OK: data_structures -> compilers : Arista creada exitosamente: data_structures -> compilers (prerequisito)\n",
      "OK: algorithms -> advanced_algorithms : Arista creada exitosamente: algorithms -> advanced_algorithms (prerequisito)\n",
      "OK: algorithms -> complexity_theory : Arista creada exitosamente: algorithms -> complexity_theory (prerequisito)\n",
      "OK: algorithms -> parallel_computing : Arista creada exitosamente: algorithms -> parallel_computing (prerequisito)\n",
      "OK: object_oriented_programming -> software_engineering : Arista creada exitosamente: object_oriented_programming -> software_engineering (prerequisito)\n",
      "OK: object_oriented_programming -> design_patterns : Arista creada exitosamente: object_oriented_programming -> design_patterns (prerequisito)\n",
      "OK: object_oriented_programming -> web_development : Arista creada exitosamente: object_oriented_programming -> web_development (prerequisito)\n",
      "OK: computer_logic -> formal_methods : Arista creada exitosamente: computer_logic -> formal_methods (prerequisito)\n",
      "OK: computer_logic -> automated_reasoning : Arista creada exitosamente: computer_logic -> automated_reasoning (prerequisito)\n",
      "OK: computer_logic -> compiler_design : Arista creada exitosamente: computer_logic -> compiler_design (prerequisito)\n",
      "OK: graph_theory -> network_algorithms : Arista creada exitosamente: graph_theory -> network_algorithms (prerequisito)\n",
      "OK: graph_theory -> distributed_systems : Arista creada exitosamente: graph_theory -> distributed_systems (prerequisito)\n",
      "OK: graph_theory -> social_networks : Arista creada exitosamente: graph_theory -> social_networks (prerequisito)\n",
      "OK: artificial_intelligence -> expert_systems : Arista creada exitosamente: artificial_intelligence -> expert_systems (prerequisito)\n",
      "OK: artificial_intelligence -> natural_language_processing : Arista creada exitosamente: artificial_intelligence -> natural_language_processing (prerequisito)\n",
      "OK: artificial_intelligence -> computer_vision : Arista creada exitosamente: artificial_intelligence -> computer_vision (prerequisito)\n",
      "OK: machine_learning -> deep_learning : Arista creada exitosamente: machine_learning -> deep_learning (prerequisito)\n",
      "OK: machine_learning -> reinforcement_learning : Arista creada exitosamente: machine_learning -> reinforcement_learning (prerequisito)\n",
      "OK: machine_learning -> neural_networks : Arista creada exitosamente: machine_learning -> neural_networks (prerequisito)\n",
      "OK: deep_learning -> computer_vision : Arista creada exitosamente: deep_learning -> computer_vision (prerequisito)\n",
      "OK: deep_learning -> natural_language_processing : Arista creada exitosamente: deep_learning -> natural_language_processing (prerequisito)\n",
      "OK: deep_learning -> generative_ai : Arista creada exitosamente: deep_learning -> generative_ai (prerequisito)\n"
     ]
    }
   ],
   "source": [
    "def add_prerequisites_from_map(graph:GraphDB, prerequisite_map:Dict[str,List[str]]) -> None:\n",
    "  \"\"\"Inserta aristas de tipo 'prerequisito' basadas en eun diccionario donde:\n",
    "  - key: subtema prerrequisito\n",
    "  - value: lista de subtemas que lo requieren\n",
    "\n",
    "  Args:\n",
    "    graph (GraphDB): instancia de GraphDB\n",
    "    prerequisite_map (Dict): diccionario con subtemas y listas de dependencias  \n",
    "  \"\"\"\n",
    "  total = 0\n",
    "  for prerequisite, topics in prerequisite_map.items():\n",
    "    for topic in topics:\n",
    "      result = graph.add_edge(\n",
    "        source_id=prerequisite,\n",
    "        target_id=topic,\n",
    "        relation_type=\"prerequisito\",\n",
    "        properties={\"explicación\": f\"{prerequisite} es prerequisito de {topic}\"},\n",
    "        directed=True\n",
    "      )\n",
    "      total += 1 if result[\"success\"] else 0 \n",
    "      status = \"OK\" if result[\"success\"] else \"ERROR\"\n",
    "      print(f\"{status}: {prerequisite} -> {topic} : {result['message']}\")\n",
    "\n",
    "# instanciar y resetar para prueba\n",
    "graph = GraphDB(\"prerequisites_graph\")\n",
    "graph.clear_database(True)\n",
    "\n",
    "# definición de los tipos de tópicos y su clasificación\n",
    "type_map = {\n",
    "  # Fundamentos matemáticos\n",
    "  \"discrete_mathematics\": [\n",
    "    \"discrete_math\", \"computer_logic\", \"graph_theory\", \"combinatorics\",\n",
    "    \"set_theory\", \"boolean_algebra\", \"number_theory\", \"formal_methods\"\n",
    "  ],\n",
    "  \n",
    "  \"continuous_mathematics\": [\n",
    "    \"calculus\", \"linear_algebra\", \"statistics\", \"numerical_methods\",\n",
    "    \"optimization\", \"probability_theory\", \"differential_equations\"\n",
    "  ],\n",
    "  \n",
    "  # Fundamentos de programación\n",
    "  \"programming_fundamentals\": [\n",
    "    \"programming_basics\", \"data_structures\", \"algorithms\", \"object_oriented_programming\",\n",
    "    \"functional_programming\", \"programming_paradigms\", \"code_design\"\n",
    "  ],\n",
    "  \n",
    "  # Inteligencia artificial\n",
    "  \"artificial_intelligence\": [\n",
    "    \"artificial_intelligence\", \"expert_systems\", \"automated_reasoning\",\n",
    "    \"knowledge_representation\", \"search_algorithms\", \"planning\"\n",
    "  ],\n",
    "  \n",
    "  \"machine_learning\": [\n",
    "    \"machine_learning\", \"deep_learning\", \"neural_networks\",\n",
    "    \"reinforcement_learning\", \"supervised_learning\", \"unsupervised_learning\"\n",
    "  ],\n",
    "}\n",
    "\n",
    "for key, topics in type_map.items():\n",
    "  for topic in topics:\n",
    "    graph.add_node(topic, key) \n",
    "\n",
    "# definición de los prerequisitos\n",
    "prerequisite_map = {\n",
    "  # Matemáticas básicas - Base fundamental\n",
    "  \"basic_math\": [\"discrete_math\", \"linear_algebra\", \"calculus\", \"statistics\"],\n",
    "  \n",
    "  # Programación fundamental\n",
    "  \"programming_basics\": [\"data_structures\", \"algorithms\", \"object_oriented_programming\"],\n",
    "  \n",
    "  # Matemáticas avanzadas\n",
    "  \"discrete_math\": [\"algorithms\", \"computer_logic\", \"cryptography\", \"graph_theory\"],\n",
    "  \"linear_algebra\": [\"machine_learning\", \"computer_graphics\", \"data_science\"],\n",
    "  \"calculus\": [\"numerical_methods\", \"optimization\", \"machine_learning\"],\n",
    "  \"statistics\": [\"data_science\", \"machine_learning\", \"artificial_intelligence\"],\n",
    "  \n",
    "  # Estructuras de datos y algoritmos\n",
    "  \"data_structures\": [\"advanced_algorithms\", \"database_design\", \"compilers\"],\n",
    "  \"algorithms\": [\"advanced_algorithms\", \"complexity_theory\", \"parallel_computing\"],\n",
    "  \n",
    "  # Paradigmas de programación\n",
    "  \"object_oriented_programming\": [\"software_engineering\", \"design_patterns\", \"web_development\"],\n",
    "  \n",
    "  # Lógica y matemáticas computacionales\n",
    "  \"computer_logic\": [\"formal_methods\", \"automated_reasoning\", \"compiler_design\"],\n",
    "  \"graph_theory\": [\"network_algorithms\", \"distributed_systems\", \"social_networks\"],\n",
    "  \n",
    "  # Inteligencia artificial y aprendizaje automático\n",
    "  \"artificial_intelligence\": [\"expert_systems\", \"natural_language_processing\", \"computer_vision\"],\n",
    "  \"machine_learning\": [\"deep_learning\", \"reinforcement_learning\", \"neural_networks\"],\n",
    "  \"deep_learning\": [\"computer_vision\", \"natural_language_processing\", \"generative_ai\"],\n",
    "}\n",
    "\n",
    "tmp = []\n",
    "for k,v in prerequisite_map.items():\n",
    "  tmp.append(k)\n",
    "  tmp.extend(v)\n",
    "\n",
    "for i in tmp:\n",
    "  graph.add_node(i, node_type=\"computer science\")\n",
    "\n",
    "def validate_topological_order(prereq_map:Dict):\n",
    "  \"Valida que el diccionario de prerequisitos no tenga ciclos (orden topológico válido)\"\n",
    "  visited = set()\n",
    "  rec_stack = set()\n",
    "  \n",
    "  def has_cycle(node):\n",
    "    if node in rec_stack:\n",
    "      return True\n",
    "    if node in visited:\n",
    "      return False\n",
    "    \n",
    "    visited.add(node)\n",
    "    rec_stack.add(node)\n",
    "    \n",
    "    # Verificar todos los cursos que dependen de este prerequisito\n",
    "    for dependent in prereq_map.get(node, []):\n",
    "      if has_cycle(dependent):\n",
    "        return True\n",
    "    \n",
    "    rec_stack.remove(node)\n",
    "    return False\n",
    "  \n",
    "  # Verificar todos los nodos\n",
    "  for node in prereq_map:\n",
    "    if node not in visited:\n",
    "      if has_cycle(node):\n",
    "        return False\n",
    "  \n",
    "  return True\n",
    "\n",
    "\n",
    "\n",
    "assert validate_topological_order(prerequisite_map)\n",
    "\n",
    "add_prerequisites_from_map(graph=graph, prerequisite_map=prerequisite_map)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
