{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c6d8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import sys \n",
    "import json\n",
    "from io import StringIO\n",
    "from abc import ABC, abstractmethod\n",
    "from enum import Enum\n",
    "from typing import Dict, List, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from langchain_ollama import (\n",
    "  OllamaLLM,\n",
    "  ChatOllama,\n",
    "  OllamaEmbeddings\n",
    ")\n",
    "from langchain_core.messages import (\n",
    "  BaseMessage,\n",
    "  AIMessage,\n",
    "  HumanMessage  \n",
    ")\n",
    "from langchain_core.prompts import (\n",
    "  ChatPromptTemplate,\n",
    "  MessagesPlaceholder  \n",
    ")\n",
    "\n",
    "\n",
    "GEMMA = \"gemma3:1b\"             # ollama gemma3:1b\n",
    "DEEPSEEK = \"deepseek-r1:1.5b\"   # ollama deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e7eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SYSTEM_PROMPT = \"\"\" \n",
    "Eres un asistente especializado capaz de responder preguntas sencillas\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2732c2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM(ABC):\n",
    "  def __init__(self, model:str, api_key:str=\"\", temperature:float=0.7):\n",
    "    self.model = model\n",
    "    self.api_key = api_key \n",
    "    self.temperature = temperature\n",
    "  \n",
    "  @abstractmethod\n",
    "  def __call__(self, query:str) -> str:\n",
    "    pass \n",
    "\n",
    "class Ollama(LLM):\n",
    "  def __init__(self, model:str, api_key:str = \"\", temperature:float = 0.7, system_prompt:str = \"\"):\n",
    "    super().__init__(model, api_key, temperature)\n",
    "    \n",
    "    try:\n",
    "      self.llm = OllamaLLM(self.model, self.temperature)\n",
    "    except Exception:\n",
    "      self.llm = OllamaLLM(model=GEMMA, temperature=0.7)\n",
    "    \n",
    "    self.system_prompt:str = system_prompt if len(system_prompt) > 0 else DEFAULT_SYSTEM_PROMPT\n",
    "    self.memory:List = []\n",
    "    \n",
    "    self.chat_prompt = ChatPromptTemplate.from_messages(\n",
    "      [\n",
    "        ('system', f'{self.system_prompt}'),\n",
    "        MessagesPlaceholder(variable_name='memory'),\n",
    "        ('human', '{query}')\n",
    "      ]\n",
    "    )\n",
    "    self.chain = self.chat_prompt | self.llm  \n",
    "  \n",
    "  def __call__(self, query:str) -> str:\n",
    "    response = self.chain.invoke(\n",
    "      {\n",
    "        \"query\": HumanMessage(query),\n",
    "        \"memory\": self.memory\n",
    "      }\n",
    "    )\n",
    "    self.memory.append(HumanMessage(content=query))\n",
    "    self.memory.append(AIMessage(content=response))\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb12eb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=GEMMA)\n",
    "llm(\"¿Qué es la Inteligencia Artificial?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69514cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseResponse:\n",
    "  \"\"\"\n",
    "  Clase base para manejar respuestas del sistema. \n",
    "  Permite almacenar información de éxito/error y datos adicionales\n",
    "  \"\"\"\n",
    "  def __init__(self, success:bool, agent:str, result:Any=None, message:str=\"\", **kwargs:Dict[str,Any]) -> None:\n",
    "    \"\"\"Inicializa la respuesta base\n",
    "\n",
    "    Args:\n",
    "      success (bool): indica si la operación fue exitosa.\n",
    "      agent (str): nombre del agente que ejecutó la operación.\n",
    "      result (Any): resultado de la operación (puede ser cualquier tipo)\n",
    "      message (str): descripción de la operación realizada. Defaults to \"\".\n",
    "    \"\"\"\n",
    "    self.success = success\n",
    "    self.agent   = agent \n",
    "    self.result  = result\n",
    "    self.message = message \n",
    "    self.extra_data = kwargs\n",
    "\n",
    "  def get_info(self) -> Dict[str,Any]:\n",
    "    \"\"\"Obtiene la información de la respuesta\n",
    "\n",
    "    Returns:\n",
    "      Dict[str,Any]: Diccionario con información básica de la respuesta\n",
    "    \"\"\"\n",
    "    info = {\n",
    "      \"success\": self.success,\n",
    "      \"agent\": self.agent,\n",
    "      \"result\": self.result,\n",
    "      \"message\": self.message\n",
    "    }\n",
    "    info.update(self.extra_data)\n",
    "    return info\n",
    "  \n",
    "  def get_data(self, key:str, default:Any=None) -> Any:\n",
    "    \"\"\"Obtiene un dato específico de los datos extra.\n",
    "\n",
    "    Args:\n",
    "      key (str): clave del dato a obtener\n",
    "      default (Any): valor por defecto si la clave no existe. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "      Any: valor del dato solicitado o el valor por defecto\n",
    "    \"\"\"\n",
    "    return self.extra_data.get(key, default)\n",
    "  \n",
    "  def __str__(self) -> str:\n",
    "    \"Representación en string de la información\"\n",
    "    status = \"SUCCESS\" if self.success else \"ERROR\"\n",
    "    return f\"[{status}] {self.agent}: {self.message}\"\n",
    "  \n",
    "  def __repr__(self) -> str:\n",
    "    \"Representación detallada de la respuesta\"\n",
    "    return f\"BaseResponse(success={self.success}, agent='{self.agent}', message='{self.message}')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeeeed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskType(Enum):\n",
    "  TEXT_GENERATION = \"generación de texto\"\n",
    "  DATASET_SEARCH = \"consulta a dataset\"\n",
    "  MATH_OPERATION = \"cálculo matemático\"\n",
    "  DOCUMENT_ANALYSIS = \"análisis de documentos\" \n",
    "  CODE_GENERATION = \"generación de código\"\n",
    "\n",
    "class TaskStatus(Enum):\n",
    "  PENDING = \"pendiente\"\n",
    "  COMPLETED = \"completado\"\n",
    "  FAILED = \"fallido\"\n",
    "\n",
    "@dataclass\n",
    "class Task:\n",
    "  task_id:str \n",
    "  task_type:TaskType\n",
    "  description:str\n",
    "  result:Optional[Any] = None\n",
    "  assigned_agent:Optional[str] = None\n",
    "  status:TaskStatus = TaskStatus.PENDING\n",
    "  error_message:Optional[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd46405",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAgent(ABC):\n",
    "  \"\"\"\n",
    "  Clase base abstracta para todos los agentes del sistema.\n",
    "  Define la interfaz común que deben implementar todos los agentes.\n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self, name:str, description:str, capabilities:List[TaskType]) -> None:\n",
    "    self.name:str = name \n",
    "    self.description:str = description\n",
    "    self.capabilities:List[TaskType] = capabilities\n",
    "  \n",
    "  @abstractmethod\n",
    "  def process(self, queries:List[str], results:List[Dict] = [], **kwargs:Dict[str,Any]) -> BaseResponse:\n",
    "    \"Método abstracto que debe implementar cada agente específico\"\n",
    "    pass \n",
    "  \n",
    "  def can_handle_task(self, task_type:TaskType) -> bool:\n",
    "    \"Verifica si el agente puede manejar un tipo específico de tarea\"\n",
    "    return task_type in self.capabilities\n",
    "  \n",
    "  def get_info(self) -> Dict[str,str]:\n",
    "    \"Retorna información básica del agente\"\n",
    "    return {\n",
    "      \"name\": self.name, \n",
    "      \"description\": self.description\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5580c5ab",
   "metadata": {},
   "source": [
    "## Ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e3c1b4",
   "metadata": {},
   "source": [
    "### Agente Especializado en Analizar y Generar Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30452733",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentTextAgent(BaseAgent):\n",
    "  \"Agente especializado en generar texto basado en una lista de documentos\"\n",
    "  \n",
    "  def __init__(self, llm: LLM, documents: List[str]):\n",
    "    super().__init__(\n",
    "      name=\"DocumentTextAgent\", \n",
    "      description=\"Genera texto y responde preguntas basándose en una colección de documentos\",\n",
    "      capabilities=[\n",
    "        TaskType.TEXT_GENERATION, \n",
    "        TaskType.DOCUMENT_ANALYSIS\n",
    "      ]\n",
    "    )\n",
    "    self.llm: LLM = llm \n",
    "    self.documents: List[str] = documents \n",
    "  \n",
    "  def process(self, queries:List[str], results:List[Dict] = [], **kwargs: Dict[str, Any]) -> BaseResponse:\n",
    "    \"Procesa una consulta basándose en los documentos disponibles\"\n",
    "    if not queries:\n",
    "      return BaseResponse(\n",
    "        success=False,\n",
    "        agent=self.name,\n",
    "        result=None,\n",
    "        message=\"No se encuentran 'queries' en los parámetros\"\n",
    "      )\n",
    "    \n",
    "    answers = []\n",
    "    for query in queries:\n",
    "      answer = self._process_query(query=query)\n",
    "      answers.append(answer)\n",
    "    \n",
    "    return BaseResponse(\n",
    "      success=True, \n",
    "      agent=self.name,\n",
    "      result=answers,\n",
    "      message=\"Procesamiento de consultas completado exitosamente\"\n",
    "    )\n",
    "  \n",
    "  def _process_query(self, query: str) -> str:\n",
    "    \"Procesa una consulta individual usando los documentos disponibles\"\n",
    "    enhanced_query = f\"\"\" \n",
    "    {query}\n",
    "    ---\n",
    "    Documentos disponibles:\n",
    "    {self.documents}\n",
    "    \"\"\"\n",
    "    response = self.llm(query=enhanced_query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900685c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=GEMMA)\n",
    "agent = DocumentTextAgent(llm, documents=[\"...\"])\n",
    "response = agent.process(queries=[\"¿qué es la inteligencia artificial?\",\"¿qué aplicaciones tiene?\"])\n",
    "\n",
    "if not response.success:\n",
    "  raise Exception(str(response))\n",
    "\n",
    "answers:List[str] = response.result\n",
    "for item in answers:\n",
    "  print(item)\n",
    "  print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603bfcf2",
   "metadata": {},
   "source": [
    "### Agente Especializado en Resolver Problemas Matemáticos Generando y Ejecutando Código Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d84a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_MathPythonAgent = \"\"\" \n",
    "Eres un asistente especializado en resolver problemas matemáticos usando Python.\n",
    "\n",
    "Tu tarea es:\n",
    "1. Analizar el problema matemático presentado\n",
    "2. Generar código Python que resuelva el problema\n",
    "3. El código debe ser seguro y ejecutable\n",
    "4. Incluye solo las operaciones matemáticas necesarias\n",
    "5. Asigna el resultado final a una variable llamada 'resultado'\n",
    "\n",
    "Ejemplo:\n",
    "Pregunta: \"¿Cuánto es 2 + 2?\"\n",
    "Código:\n",
    "```python\n",
    "resultado = 2 + 2\n",
    "```\n",
    "\n",
    "IMPORTANTE: Responde SOLO con el código Python, sin explicaciones adicionales.\n",
    "\"\"\"\n",
    "\n",
    "class MathPythonAgent(BaseAgent):\n",
    "  \"Agente especializado en resolver problemas matemáticos y ejecutando código Python\"\n",
    "  \n",
    "  def __init__(self, llm: LLM, documents: List[str]):\n",
    "    super().__init__(\n",
    "      name=\"MathPythonAgent\", \n",
    "      description=\"Resuelve problemas matemáticos generando y ejecutando código Python\",\n",
    "      capabilities=[\n",
    "        TaskType.CODE_GENERATION, \n",
    "        TaskType.MATH_OPERATION\n",
    "      ]\n",
    "    )\n",
    "    self.llm: LLM = llm \n",
    "    self.documents: List[str] = documents \n",
    "  \n",
    "  def process(self, queries:List[str], results:List[Dict] = [], **kwargs: Dict[str, Any]) -> BaseResponse:\n",
    "    \"Procesa una consulta basándose en los documentos disponibles\"\n",
    "    if not queries:\n",
    "      return BaseResponse(\n",
    "        success=False,\n",
    "        agent=self.name, \n",
    "        result=None,\n",
    "        message=\"No se encuentran 'queries' en los parámetros\"\n",
    "      )\n",
    "    \n",
    "    answers = [ ]\n",
    "    for query in queries:\n",
    "      answer = self._process_query(query=query)\n",
    "      answers.append(answer)\n",
    "    \n",
    "    return BaseResponse(\n",
    "      success=True,\n",
    "      agent=self.name,\n",
    "      result=answers,\n",
    "      message=\"Procesamiento de cálculos matemáticos completado\"\n",
    "    )\n",
    "    \n",
    "  def _process_query(self, query: str) -> str:\n",
    "    \"Procesa una consulta individual para generar código Python\"\n",
    "    enhanced_query = f\"\"\" \n",
    "    {prompt_MathPythonAgent}\n",
    "    \n",
    "    Problema: {query}\n",
    "    \n",
    "    Documentos de referencia:\n",
    "    {self.documents}\n",
    "    \"\"\"\n",
    "    response = self.llm(query=enhanced_query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8837fe11",
   "metadata": {},
   "source": [
    "## Agent Engine\n",
    "\n",
    "**Agent Engine**: Motor Central que gestiona múltiples agentes y decide cuál usar para cada consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f627da5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_AgentEngine = \"\"\"\n",
    "Tienes que elegir el agente más apropiado para responder la siguiente consulta.\n",
    "Clasificada como: {task_type}\n",
    "\n",
    "Agentes disponibles:\n",
    "{agents_info}\n",
    "\n",
    "Consulta del usuario: \"{query}\"\n",
    "\n",
    "Responde ÚNICAMENTE con el nombre exacto del agente más apropiado (sin explicaciones adicionales).\n",
    "\"\"\"\n",
    "\n",
    "class TaskManager:\n",
    "  def __init__(self, llm: LLM):\n",
    "    self.task_queue: List[Task] = []\n",
    "    self.agents: Dict[str, BaseAgent] = {}\n",
    "    self.completed_tasks: List[Task] = []\n",
    "    self.failed_tasks: List[Task] = []\n",
    "    self.task_counter: int = 0\n",
    "    self.llm: LLM = llm  # LLM para selección de agentes\n",
    "  \n",
    "  def add_agent(self, agent: BaseAgent) -> BaseResponse:\n",
    "    \"Registra un nuevo agente en el sistema\"\n",
    "    try:\n",
    "      self.agents[agent.name] = agent\n",
    "      return BaseResponse(\n",
    "        success=True,\n",
    "        agent=agent.name,\n",
    "        result=None,\n",
    "        message=\"Agente registrado exitosamente\"\n",
    "      )\n",
    "    except Exception as e:\n",
    "      return BaseResponse(\n",
    "        success=False,\n",
    "        agent=agent.name,\n",
    "        result=None,\n",
    "        message=f\"Error al registrar agente: {str(e)}\"\n",
    "      )\n",
    "  \n",
    "  def add_task(self, task:Task) -> None:\n",
    "    \"Añade una nueva tarea en el sistema\"\n",
    "    self.task_queue.append(task)\n",
    "  \n",
    "  def get_available_agents(self) -> Dict[str, Dict[str, Any]]:\n",
    "    \"Devuelve la información de todos los agentes disponibles\"\n",
    "    return {name: agent.get_info() for name, agent in self.agents.items()}\n",
    "  \n",
    "  def select_agent_for_task(self, task: Task) -> Optional[BaseAgent]:\n",
    "    \"Selecciona el agente más apropiado para una tarea específica\"\n",
    "    if not self.agents:\n",
    "      return None\n",
    "    \n",
    "    # Filtrar agentes que pueden manejar el tipo de tarea\n",
    "    capable_agents = [\n",
    "      agent for agent in self.agents.values() \n",
    "      if agent.can_handle_task(task.type)\n",
    "    ]\n",
    "    \n",
    "    if not capable_agents:\n",
    "      return None\n",
    "    \n",
    "    if len(capable_agents) == 1:\n",
    "      return capable_agents[0]\n",
    "    \n",
    "    # Si hay múltiples agentes capaces, usar LLM para seleccionar el mejor\n",
    "    agents_info = \"\\n\".join([\n",
    "      f\"- {agent.name}: {agent.description} (Capacidades: {[cap.value for cap in agent.capabilities]})\"\n",
    "      for agent in capable_agents\n",
    "    ])\n",
    "    \n",
    "    selection_prompt = prompt_AgentEngine.format(\n",
    "      agents_info=agents_info,\n",
    "      query=task.description,\n",
    "      task_type=task.type.value\n",
    "    ) \n",
    "    \n",
    "    try:\n",
    "      response = self.llm(selection_prompt).strip()\n",
    "      \n",
    "      # Buscar el agente por nombre en la respuesta\n",
    "      for agent in capable_agents:\n",
    "        if agent.name in response:\n",
    "          return agent\n",
    "      \n",
    "      # Si no encuentra coincidencia exacta, devolver el primer agente capaz\n",
    "      return capable_agents[0]\n",
    "      \n",
    "    except Exception:\n",
    "      # En caso de error, devolver el primer agente capaz\n",
    "      return capable_agents[0]\n",
    "  \n",
    "  def assign_task_to_agent(self, task: Task, agent: BaseAgent) -> bool:\n",
    "    \"Asigna una tarea específica a un agente\"\n",
    "    try:\n",
    "      task.assign_to_agent(agent.name)\n",
    "      return True\n",
    "    except Exception:\n",
    "      return False\n",
    "  \n",
    "  def execute_task(self, task: Task, results:List[Dict]) -> BaseResponse:\n",
    "    \"Ejecuta una tarea usando el agente asignado\"\n",
    "    if not task.assigned_agent:\n",
    "      return BaseResponse(\n",
    "        success=False,\n",
    "        agent=\"TaskManager\",\n",
    "        result=None,\n",
    "        message=\"Tarea no tiene agente asignado\"\n",
    "      )\n",
    "    \n",
    "    agent:BaseAgent = self.agents.get(task.assigned_agent)\n",
    "    if not agent:\n",
    "      return BaseResponse(\n",
    "        success=False,\n",
    "        agent=\"TaskManager\",\n",
    "        result=None,\n",
    "        message=f\"Agente {task.assigned_agent} no encontrado\"\n",
    "      )\n",
    "    \n",
    "    try:\n",
    "      # Ejecutar la tarea con el agente\n",
    "      response = agent.process(\n",
    "        queries=[task.description],\n",
    "        results=results\n",
    "      )\n",
    "      \n",
    "      if response.success:\n",
    "        task.mark_as_completed(response.result)\n",
    "        self.completed_tasks.append(task)\n",
    "      else:\n",
    "        task.mark_as_failed(response.message)\n",
    "        self.failed_tasks.append(task)\n",
    "      \n",
    "      return response\n",
    "      \n",
    "    except Exception as e:\n",
    "      task.mark_as_failed(str(e))\n",
    "      self.failed_tasks.append(task)\n",
    "      return BaseResponse(\n",
    "        success=False,\n",
    "        agent=task.assigned_agent,\n",
    "        result=None,\n",
    "        message=f\"Error al ejecutar tarea: {str(e)}\"\n",
    "      )\n",
    "  \n",
    "  def get_pending_tasks(self) -> List[Task]:\n",
    "    \"Obtiene todas las tareas pendientes\"\n",
    "    return [task for task in self.task_queue if task.status == TaskStatus.PENDING]\n",
    "  \n",
    "  def get_task_status(self) -> Dict[str, int]:\n",
    "    \"Obtiene un resumen del estado de las tareas\"\n",
    "    all_tasks = self.task_queue + self.completed_tasks + self.failed_tasks\n",
    "    return {\n",
    "      \"pending\": len([t for t in all_tasks if t.status == TaskStatus.PENDING]),\n",
    "      \"in_progress\": len([t for t in all_tasks if t.status == TaskStatus.IN_PROGRESS]),\n",
    "      \"completed\": len([t for t in all_tasks if t.status == TaskStatus.COMPLETED]),\n",
    "      \"failed\": len([t for t in all_tasks if t.status == TaskStatus.FAILED])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f82eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SYSTEM_PROMPT = \"\"\" \n",
    "Eres un asistente especializado capaz de responder preguntas sencillas\n",
    "\"\"\"\n",
    "\n",
    "DECOMPOSITION_SYSTEM_PROMPT = \"\"\" \n",
    "Eres un experto en descomposición de problemas. Tu tarea es tomar un problema complejo y dividirlo en subproblemas más pequeños y manejables.\n",
    "\n",
    "Tener en cuenta:\n",
    "- Cada subproblema debe ser específico y manejable\n",
    "- Los subproblemas deben seguir un orden lógico\n",
    "- Juntos, los subproblemas deben cubrir completamente el problema original\n",
    "\n",
    "Formato de respuesta:\n",
    "- Responde ÚNICAMENTE con una lista de subproblemas\n",
    "- Un subproblema por línea\n",
    "- Usa viñetas (`-`)\n",
    "\n",
    "Ejemplo de salida:\n",
    "- subproblema 1\n",
    "- subproblema 2\n",
    "- subproblema 3\n",
    "\"\"\"\n",
    "\n",
    "SELECT_PROMPT = \"\"\" \n",
    "Eres un experto en clasificar si una entrada de usuario es un subproblema de un problema mucho mayor. \n",
    "\n",
    "Formato de respuesta: \n",
    "- Responde ÚNICAMENTE con TRUE o FALSE\n",
    "\"\"\"\n",
    "\n",
    "CONSTRUCT_PROMPT = \"\"\" \n",
    "Eres un experto en crear preguntas. Tu tarea es tomar una entrada del usuario y generar a partir de esta una pregunta o problema.\n",
    "\n",
    "Instrucciones:\n",
    "- Generar la pregunta sencilla, corta y clara.\n",
    "\"\"\"\n",
    "\n",
    "def decompose_problem(problem:str, verbose:bool=False, k:int=3) -> List[str]:\n",
    "  \"\"\"Descompone un problema complejo en una lista de subproblemas más manejables.\n",
    "\n",
    "  Args:\n",
    "    problem (str): el problema principal a descomponer\n",
    "\n",
    "  Returns:\n",
    "    List[str]: lista de subproblemas que juntos resuelven el problema original\n",
    "  \"\"\"\n",
    "  # crear una instancia temporal para descomposición\n",
    "  decomposer = ChatOllama(model=GEMMA, temperature=0.2) # temperatura más baja para mayor consistencia\n",
    "  decomposition_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', DECOMPOSITION_SYSTEM_PROMPT),\n",
    "    ('human', f'Descompone el siguiente problema en subproblemas:\\n\\n{problem}')\n",
    "  ])\n",
    "  chain = decomposition_prompt | decomposer\n",
    "  response = chain.invoke({\"problem\":problem}).content\n",
    "  \n",
    "  if verbose: print(response)\n",
    "  \n",
    "  subproblems = []\n",
    "  lines = response.strip().split('\\n')\n",
    "  for line in lines:\n",
    "    line = line.strip()\n",
    "    \n",
    "    # limpiar viñetas y numeración\n",
    "    if line.startswith('- '):\n",
    "      subproblem = line[2:].strip()\n",
    "    elif line.startswith('• '):\n",
    "      subproblem = line[2:].strip()\n",
    "    elif re.match(r'^\\d+\\.\\s*', line):\n",
    "      subproblem = re.sub(r'^\\d+\\.\\s*', '', line).strip()\n",
    "    elif line and not line.startswith('#'):\n",
    "      subproblem = line.strip()\n",
    "    else:\n",
    "      continue\n",
    "    \n",
    "    if subproblem and len(subproblem) > 5:   # filtrar lineas muy cortas\n",
    "      subproblems.append(subproblem)\n",
    "    \n",
    "  if not subproblems:\n",
    "    if k > 0:\n",
    "      return decompose_problem(problem=problem, verbose=verbose, k=k-1)\n",
    "    else:\n",
    "      raise Exception(\"ERROR: no se pudo dividir el problema\")\n",
    "    \n",
    "  return subproblems\n",
    "\n",
    "def select_problem(problem:str, subproblem:str, verbose:bool=False) -> bool:\n",
    "  selector = ChatOllama(model=GEMMA, temperature=0.2) # temperatura más baja para mayor consistencia\n",
    "  selection_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', SELECT_PROMPT),\n",
    "    ('human', '{problem}')\n",
    "  ])\n",
    "  chain = selection_prompt | selector\n",
    "  response = chain.invoke({\"problem\":f\"Problema original:\\n\\n{problem}\\n\\nEntrada de usuario:\\n\\n{subproblem}\"}).content\n",
    "  \n",
    "  if verbose: print(response)\n",
    "  \n",
    "  lines = response.strip().split('\\n')\n",
    "  if len(lines) == 1: \n",
    "    try: \n",
    "      output = True if lines[0] == \"TRUE\" else False if lines[0] == \"FALSE\" else None\n",
    "      if output == None:\n",
    "        return False\n",
    "        # raise Exception(f\"ERROR al convertir a bool: {response}\")\n",
    "      return output\n",
    "    except:\n",
    "      return False\n",
    "      # raise Exception(f\"ERROR al convertir a bool: {response}\")\n",
    "  return False\n",
    "  # raise Exception(f\"ERROR al responder adecuadamente: {response}\")\n",
    "\n",
    "def construct_task(subproblem:str, verbose:bool=False) -> str:\n",
    "  selector = ChatOllama(model=GEMMA, temperature=0.5) # temperatura más baja para mayor consistencia\n",
    "  selection_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', CONSTRUCT_PROMPT),\n",
    "    ('human', 'Entrada del usuario: {problem}')\n",
    "  ])\n",
    "  chain = selection_prompt | selector\n",
    "  response = chain.invoke({\"problem\":subproblem}).content\n",
    "  \n",
    "  if verbose: print(response)\n",
    "  \n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c510eaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFICATION_PROMPT = \"\"\" \n",
    "Analiza la siguiente descripción de tarea y determina cuál de estos tipos de tarea es el más adecuado:\n",
    "\n",
    "TIPOS DE TAREA DISPONIBLES:\n",
    "1. TEXT_GENERATION (generación de texto) - Para crear contenido textual, escribir artículos, resúmenes, emails, etc.\n",
    "2. DATASET_SEARCH (consulta a dataset) - Para buscar información específica en datasets, consultas SQL, filtros de datos, etc.\n",
    "3. MATH_OPERATION (cálculo matemático) - Para realizar cálculos, operaciones matemáticas, análisis numérico, etc.\n",
    "4. DOCUMENT_ANALYSIS (análisis de documentos) - Para analizar, extraer información o procesar documentos existentes\n",
    "5. CODE_GENERATION (generación de código) - Para escribir código, programar funciones, crear scripts, etc.\n",
    "\n",
    "DESCRIPCIÓN DE LA TAREA:\n",
    "\"{description}\"\n",
    "\n",
    "INSTRUCCIONES:\n",
    "- Responde ÚNICAMENTE con el nombre del tipo de tarea (por ejemplo: TEXT_GENERATION)\n",
    "- No incluyas explicaciones adicionales\n",
    "- Si hay ambigüedad, elige el tipo más específico y relevante\n",
    "- Considera las palabras clave y el contexto de la descripción\n",
    "\n",
    "RESPUESTA:\n",
    "\"\"\"\n",
    "\n",
    "def get_task_type_by_description(description:str) -> TaskType:\n",
    "  \"Clasifica el tipo de task según los tipos de task disponibles\"\n",
    "  llm = Ollama(model=GEMMA, temperature=0.3)\n",
    "  response = llm(CLASSIFICATION_PROMPT.format(description=description)).strip().upper()\n",
    "  task_type_mapping: Dict[str, TaskType] = {\n",
    "    \"TEXT_GENERATION\": TaskType.TEXT_GENERATION,\n",
    "    \"DATASET_SEARCH\": TaskType.DATASET_SEARCH,\n",
    "    \"MATH_OPERATION\": TaskType.MATH_OPERATION,\n",
    "    \"DOCUMENT_ANALYSIS\": TaskType.DOCUMENT_ANALYSIS,\n",
    "    \"CODE_GENERATION\": TaskType.CODE_GENERATION\n",
    "  }\n",
    "  \n",
    "  if response in task_type_mapping:\n",
    "    return task_type_mapping[response]\n",
    "  \n",
    "  return _classify_by_keywords(description)\n",
    "\n",
    "\n",
    "\n",
    "def _classify_by_keywords(description: str, llm_response: str = \"\") -> TaskType:\n",
    "  \"\"\"Función auxiliar que clasifica por palabras clave como fallback.\n",
    "    \n",
    "  Args:\n",
    "    description (str): Descripción de la tarea\n",
    "    llm_response (str): Respuesta del LLM (opcional)\n",
    "        \n",
    "  Returns:\n",
    "    TaskType: Tipo de tarea clasificado\n",
    "  \"\"\"\n",
    "    \n",
    "  # Convertir a minúsculas para comparación\n",
    "  desc_lower = description.lower()\n",
    "  response_lower = llm_response.lower()\n",
    "    \n",
    "  # Palabras clave por categoría\n",
    "  keywords: Dict[TaskType, List[str]] = {\n",
    "    TaskType.CODE_GENERATION: [\n",
    "      \"código\", \"programar\", \"script\", \"función\", \"algoritmo\", \n",
    "      \"python\", \"implementar\", \"desarrollar\", \"crear función\", \"generar código\"\n",
    "    ],\n",
    "    TaskType.MATH_OPERATION: [\n",
    "      \"calcular\", \"matemática\", \"operación\", \"suma\", \"resta\",\n",
    "      \"multiplicación\", \"división\", \"estadística\", \"análisis numérico\",\n",
    "      \"ecuación\", \"fórmula\", \"porcentaje\", \"promedio\"\n",
    "    ],\n",
    "    TaskType.DATASET_SEARCH: [\n",
    "      \"dataset\", \"datos\", \"buscar en\", \"consultar\", \"filtrar\",\n",
    "      \"base de datos\", \"csv\", \"tabla\", \"registros\", \"consulta sql\",\n",
    "      \"encontrar información\", \"extraer datos\"\n",
    "    ],\n",
    "    TaskType.DOCUMENT_ANALYSIS: [\n",
    "      \"analizar documento\", \"revisar documento\", \"extraer información\",\n",
    "      \"procesar archivo\", \"leer documento\", \"analizar texto\",\n",
    "      \"interpretar\", \"evaluar documento\", \"examinar\"\n",
    "    ],\n",
    "    TaskType.TEXT_GENERATION: [\n",
    "      \"escribir\", \"generar texto\", \"redactar\", \"crear contenido\",\n",
    "      \"artículo\", \"resumen\", \"email\", \"carta\", \"descripción\",\n",
    "      \"narrativa\", \"historia\", \"blog\", \"contenido\"\n",
    "    ]\n",
    "  }\n",
    "  \n",
    "  # Buscar en la respuesta del LLM primero\n",
    "  for task_type, words in keywords.items():\n",
    "    for word in words:\n",
    "      if word in response_lower:\n",
    "        return task_type\n",
    "    \n",
    "  # Buscar en la descripción original\n",
    "  task_scores: Dict[TaskType, int] = {task_type: 0 for task_type in TaskType}\n",
    "  \n",
    "  for task_type, words in keywords.items():\n",
    "    for word in words:\n",
    "      if word in desc_lower:\n",
    "        task_scores[task_type] += 1\n",
    "    \n",
    "  # Retornar el tipo con mayor puntuación\n",
    "  if max(task_scores.values()) > 0:\n",
    "    return max(task_scores, key=task_scores.get)\n",
    "    \n",
    "  # Default si no se encuentra coincidencia\n",
    "  return TaskType.TEXT_GENERATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab12ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class AgentEngine:\n",
    "  \"\"\"\n",
    "  Interfaz principal donde TaskManager y los agentes se comunican \n",
    "  para resolver problemas complejos\n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self, llm: LLM):\n",
    "    self.task_manager = TaskManager(llm)\n",
    "    self.llm: LLM = llm\n",
    "    self.execution_history: List[Dict[str, Any]] = []\n",
    "  \n",
    "  def register_agent(self, agent: BaseAgent) -> BaseResponse:\n",
    "    \"\"\"Registra un nuevo agente en el sistema\"\"\"\n",
    "    return self.task_manager.add_agent(agent)\n",
    "  \n",
    "  def decompose_complex_problem(self, problem: str) -> List[Task]:\n",
    "    \"Descompone un problema complejo en tareas más pequeñas. Retorna una lista de Task de cada tarea que debe realizarse\"\n",
    "    \n",
    "    subproblems = decompose_problem(problem=problem, verbose=False)\n",
    "    print(subproblems)\n",
    "    selections = [subproblem for subproblem in subproblems if select_problem(problem=problem, subproblem=subproblem, verbose=False)]\n",
    "    print(selections)\n",
    "    tasks_defs = [construct_task(select) for select in selections  ]\n",
    "    print(tasks_defs)\n",
    "    \n",
    "    tasks:List[Task] = []\n",
    "    for i,task_def in enumerate(tasks_defs):\n",
    "      tasks.append(\n",
    "        Task(\n",
    "          task_id=i,\n",
    "          task_type=get_task_type_by_description(task_def),\n",
    "          description=task_def\n",
    "        )\n",
    "      )\n",
    "    \n",
    "    return tasks\n",
    "    \n",
    "  def run_cycle(self, complex_problem: str) -> BaseResponse:\n",
    "    \"\"\"Ejecuta un ciclo completo del sistema para resolver un problema complejo\n",
    "    \n",
    "    Args:\n",
    "      complex_problem (str): Descripción del problema complejo a resolver\n",
    "      \n",
    "    Returns:\n",
    "      BaseResponse: Respuesta con el resultado del procesamiento\n",
    "    \"\"\"\n",
    "    try:\n",
    "      # 1. descomponer el problema complejo en tareas\n",
    "      tasks = self.decompose_complex_problem(complex_problem)\n",
    "      \n",
    "      # 2. crear tareas en el TaskManager\n",
    "      created_tasks = []\n",
    "      for task in tasks:\n",
    "        self.task_manager.add_task(task)\n",
    "        created_tasks.append(task)\n",
    "      \n",
    "      results = []\n",
    "      for task in created_tasks:\n",
    "        # seleccionar agente apropiado\n",
    "        selected_agent = self.task_manager.select_agent_for_task(task)\n",
    "        \n",
    "        if not selected_agent:\n",
    "          task.mark_as_failed(\"No se encontró agente apropiado\")\n",
    "          continue\n",
    "        \n",
    "        # asignar tarea al agente\n",
    "        self.task_manager.assign_task_to_agent(task, selected_agent)\n",
    "        \n",
    "        # ejecutar tarea\n",
    "        execution_result = self.task_manager.execute_task(task, results)\n",
    "        results.append({\n",
    "          \"task_id\": task.id,\n",
    "          \"agent\": selected_agent.name,\n",
    "          \"result\": execution_result.result,\n",
    "          \"success\": execution_result.success,\n",
    "          \"message\": execution_result.message\n",
    "        })\n",
    "        \n",
    "        #TODO actualizar tareas a partir de los resultados de la tarea ejecutada\n",
    "      \n",
    "      # 4. Consolidar resultados\n",
    "      successful_results = [r for r in results if r[\"success\"]]\n",
    "      failed_results = [r for r in results if not r[\"success\"]]\n",
    "      \n",
    "      # 5. Registrar en historial\n",
    "      execution_record = {\n",
    "        \"problem\": complex_problem,\n",
    "        \"tasks_created\": len(created_tasks),\n",
    "        \"tasks_completed\": len(successful_results),\n",
    "        \"tasks_failed\": len(failed_results),\n",
    "        \"results\": results,\n",
    "        \"task_status\": self.task_manager.get_task_status()\n",
    "      }\n",
    "      self.execution_history.append(execution_record)\n",
    "      \n",
    "      # 6. Generar respuesta final\n",
    "      if successful_results:\n",
    "        final_result = {\n",
    "          \"problem\": complex_problem,\n",
    "          \"solutions\": [r[\"result\"] for r in successful_results],\n",
    "          \"execution_summary\": execution_record\n",
    "        }\n",
    "        \n",
    "        return BaseResponse(\n",
    "          success=True,\n",
    "          agent=\"AgentEngine\",\n",
    "          result=final_result,\n",
    "          message=f\"Problema resuelto exitosamente. {len(successful_results)} tareas completadas.\"\n",
    "        )\n",
    "      else:\n",
    "        return BaseResponse(\n",
    "          success=False,\n",
    "          agent=\"AgentEngine\",\n",
    "          result=execution_record,\n",
    "          message=\"No se pudieron completar las tareas necesarias para resolver el problema\"\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "      return BaseResponse(\n",
    "        success=False,\n",
    "        agent=\"AgentEngine\",\n",
    "        result=None,\n",
    "        message=f\"Error durante la ejecución del ciclo: {str(e)}\"\n",
    "      )\n",
    "  \n",
    "  def get_execution_history(self) -> List[Dict[str, Any]]:\n",
    "    \"Obtiene el historial de ejecuciones\"\n",
    "    return self.execution_history\n",
    "  \n",
    "  def get_system_status(self) -> Dict[str, Any]:\n",
    "    \"Obtiene el estado general del sistema\"\n",
    "    return {\n",
    "      \"registered_agents\": len(self.task_manager.agents),\n",
    "      \"available_agents\": list(self.task_manager.agents.keys()),\n",
    "      \"task_status\": self.task_manager.get_task_status(),\n",
    "      \"execution_history_count\": len(self.execution_history)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45a5a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(\n",
    "  model=GEMMA,\n",
    "  system_prompt=\"Eres un asistente inteligente que ayuda a resolver problemas complejos\"\n",
    ")\n",
    "\n",
    "engine = AgentEngine(llm)\n",
    "\n",
    "sample_documents = [\n",
    "  \"\"\"\n",
    "# Generación de Números Aleatorios\n",
    "  \n",
    "La **generación de números aleatorios** se puede lograr a partir de la \n",
    "*simulación de variables aleatorias*. Esta simulación consiste en generar \n",
    "valores de una distribución específica (normal, exponencial, Poisson, \n",
    "etc.) y transformarlos en *números pseudoaleatorios uniformes* ($X \\sim U(0,1)$). \n",
    "La simulación de un modelo basado en números aleatorios consiste en la construcción \n",
    "de un programa computacional que permite obtener los valores de salida para distintos\n",
    "valores de las variables de entrada con el objetivo de obtener conclusiones del sistema \n",
    "que apoyen la toma de decisiones (explicar y/o predecir el comportamiento del sistema)\n",
    "\"\"\",\n",
    "\"\"\" \n",
    "# Aplicación de los Números Aleatorios\n",
    "## Simulación y Modelación\n",
    "\n",
    "Los números aleatorios permiten a los modelos matemáticos representar con mayor \n",
    "fidelidad la realidad, especialmente cuando se trata de simular entornos complejos \n",
    "donde intervienen numerosas variables impredecibles. Esto es particularmente relevante en: \n",
    "\n",
    "- Simulaciones meteorológicas y climáticas \n",
    "- Modelado de comportamientos humanos y sociales \n",
    "- Simulación de fenómenos físicos complejos \n",
    "- Pruebas de rendimiento de sistemas informáticos \n",
    "\n",
    "Estas aplicaciones aprovechan la capacidad de los números aleatorios para reflejar \n",
    "la incertidumbre inherente a los sistemas naturales y humanos, permitiendo la \n",
    "creación de modelos predictivos más robustos y realistas. \n",
    "\n",
    "## Juegos y Entretenimiento\n",
    "Una de las aplicaciones más visibles y cotidianas es en la industria del entretenimiento: \n",
    "- Juegos de azar (loterías, casinos virtuales)\n",
    "- Videojuegos (para generar eventos, comportamientos de NPCs, generación procedural de niveles)\n",
    "- Aplicaciones de sorteos digitales\n",
    "\n",
    "En estos contextos, la percepción de justicia y equilibrio está directamente vinculada a \n",
    "la calidad de la aleatoriedad generada\n",
    "  \"\"\"\n",
    "]\n",
    "\n",
    "agent1 = DocumentTextAgent(\n",
    "  llm=llm,\n",
    "  documents=sample_documents\n",
    ")\n",
    "agent2 = MathPythonAgent(\n",
    "  llm=llm,\n",
    "  documents=sample_documents\n",
    ")\n",
    "\n",
    "r_register1 = engine.register_agent(agent1)\n",
    "r_register2 = engine.register_agent(agent2)\n",
    "print(f\"Resultado 1: {r_register1}\")\n",
    "print(f\"Resultado 2: {r_register2}\")\n",
    "\n",
    "system_status = engine.get_system_status()\n",
    "print(system_status)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac6430b",
   "metadata": {},
   "source": [
    "**Ejemplo 1**: Descomposición de problemas complejos en tareas sencillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9d440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = \"\"\"Haz un analisis completo de cómo funciona la Inteligencia Artificial\n",
    "1. Definición de qué es la inteligencia artificial\n",
    "2. Aplicación\n",
    "3. Ejemplos \n",
    "4. Genera un código sencillo en Python de cómo trabaja la Inteligencia Artificial\n",
    "\"\"\"\n",
    "\n",
    "result = engine.decompose_complex_problem(problem=problem)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e490ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in result:\n",
    "  print(item)\n",
    "  print(\"==========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1a0aa0",
   "metadata": {},
   "source": [
    "**Ejemplo 3**: Problema complejo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9860680",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = \"\"\" \n",
    "Crea un reporte que combine\n",
    "1. Análisis teórico de cómo funciona una variable aleatoria \n",
    "2. Genera un código en Python cómo se genera una variable aleatoria\n",
    "\"\"\"\n",
    "result = engine.run_cycle(problem)\n",
    "\n",
    "if result.success:\n",
    "  print(f\"Message: {result.message}\")\n",
    "  \n",
    "  solutions = result.result.get(\"solutions\", [])\n",
    "  for i, solution in enumerate(solutions, 1):\n",
    "    print(f\"Solucion {i}:\")\n",
    "    if isinstance(solution, list):\n",
    "      for j, answer in enumerate(solution, 1):\n",
    "        print(f\" {j}. {answer}\")\n",
    "    else:\n",
    "      print(f\" {solution}\")\n",
    "else:\n",
    "  print(\"ERROR\")\n",
    "  print(f\"  {result.message}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
