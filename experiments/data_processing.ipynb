{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45095913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from uuid import uuid4\n",
    "from typing import List\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaLLM,OllamaEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6e09171",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_of_documents = \"..\\\\doc\\\\original\"\n",
    "path_to_export_md = \"..\\\\doc\\\\md\"\n",
    "persist_directory = \"..\\\\chroma\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864e4a8a",
   "metadata": {},
   "source": [
    "## Recursive Character Splitting\n",
    "\n",
    "> TODO: Semantic Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c6d24ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_character_splitting(text:str, source:str, chunk_size:int = 1000, percentage=0.2) -> List[Document]:\n",
    "  splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=int(chunk_size*percentage)\n",
    "  )\n",
    "  chunks:List[str] = splitter.split_text(text=text)\n",
    "  return [ Document(page_content=chunk, metadata={\"source\": source}) for chunk in chunks ]\n",
    "\n",
    "def read_document(doc:str) -> str:\n",
    "  loader = PyPDFLoader(doc)\n",
    "  pages = [page.page_content for page in loader.lazy_load()]\n",
    "  return \", \".join(pages)\n",
    "\n",
    "def load_documents() -> List[str]:\n",
    "  dir = os.listdir(path_of_documents)\n",
    "  dir = [ path_of_documents + \"\\\\\" + dir[i] for i in range(len(dir)) ]\n",
    "  return dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba87df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_chunks(chunks:List[Document]) -> None:\n",
    "  for i,chunk in enumerate(chunks):\n",
    "    print(\"\\n\\n\")\n",
    "    print(f\"--------> Chunk {i+1} <--------\")\n",
    "    print(chunk)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "596be1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = load_documents()\n",
    "result = []\n",
    "for dir in dirs:\n",
    "  text = read_document(dir)\n",
    "  chunks= recursive_character_splitting(\" \".join(text), dir)\n",
    "  result.extend(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0600cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_chunks(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f568f92c",
   "metadata": {},
   "source": [
    "## Memory as VectorStore and Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3327b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(\n",
    "  model = \"mxbai-embed-large\"\n",
    ")\n",
    "vs = InMemoryVectorStore.from_documents(\n",
    "  result, \n",
    "  embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9358ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vs.as_retriever()\n",
    "retrieved_documents = retriever.invoke(\"¿Qué es un número complejo?\")\n",
    "\n",
    "print(len(retrieved_documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671d8f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,r_doc in enumerate(retrieved_documents):\n",
    "  print(f\"=====> Document {i+1} <=====\")\n",
    "  print(r_doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b13b30",
   "metadata": {},
   "source": [
    "## Map Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f81f2fd",
   "metadata": {},
   "source": [
    "![](../resources/summary_of_data.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcbefb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\" \n",
    "Resume los temas de los siguientes fragmentos de un documento\n",
    "\n",
    "{documents} \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a206ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMMA = \"gemma3:1b\"             # ollama gemma3:1b\n",
    "#DEEPSEEK = \"deepseek-r1:1.5b\"   # ollama deepseek-r1:1.5b\n",
    "\n",
    "llm = OllamaLLM(GEMMA, temperature=0.8)\n",
    "llm.invoke(\"2+2?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
