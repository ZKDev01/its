{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e1355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict, Optional\n",
    "from dataclasses import dataclass\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import BaseMessage, AIMessage, HumanMessage\n",
    "\n",
    "GEMMA = \"gemma3:1b\"\n",
    "DEEPSEEK = \"deepseek-r1:1.5b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d899b670",
   "metadata": {},
   "source": [
    "# Personalized AI Study Plan Generator\n",
    "Agente LLM para generar planes de estudio personalizados. A continuación se presenta:\n",
    "- `StudentProfile`: Clase que almacena el perfil del estudiante, incluyendo principalmente fortalezas y debilidades\n",
    "- `StudyPlanner`: Agente que genera planes de estudio estructurados basándose en: \n",
    "  - El tema que quiere estudiar el usuario\n",
    "  - El perfil académico del estudiante \n",
    "- `ChatPlanner`: Agente conversacional que maneja la interacción con el usuario y coordina con el agente de planificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c3d2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class StudentProfile:\n",
    "  \"\"\"Perfil del estudiante con sus fortalezas, debilidades y nivel de aprendizaje\n",
    "\n",
    "  Args:\n",
    "    strengths (List[str]): temas que domina bien\n",
    "    weaknesses (List[str]): temas que necesita reforzar\n",
    "    difficulty_level (str): básico, intermedio, avanzado\n",
    "  \"\"\"\n",
    "  strengths: List[str]   \n",
    "  weaknesses: List[str] \n",
    "  difficulty_level: str \n",
    "  \n",
    "  def to_dict(self) -> Dict:\n",
    "    return {\n",
    "      \"strengths\": self.strengths,\n",
    "      \"weaknesses\": self.weaknesses,\n",
    "      \"difficulty_level\": self.difficulty_level,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "294a211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "planning_prompt = \"\"\" \n",
    "Eres un asistente experto en planificación educativa y diseño curricular.\n",
    "Tu tarea es crear planes de estudio personalizados basándose en:\n",
    "1. El tema que el estudiante quiere aprender\n",
    "2. El perfil académico del estudiante (fortalezas y debilidades)\n",
    "\n",
    "INSTRUCCIONES:\n",
    "- Analiza las debilidades del estudiante y priorízalas como prerequisitos\n",
    "- Estructura el plan de manera jerárquica\n",
    "- Incluye estimaciones de tiempo para cada sección\n",
    "- Adapta la complejidad al nivel del estudiante\n",
    "- Mantén coherencia pedagógica (de lo simple a lo complejo)\n",
    "\n",
    "FORMATO DE RESPUESTA OBLIGATORIO:\n",
    "Debes responder ÚNICAMENTE con un JSON válido en el siguiente formato exacto:\n",
    "{{\n",
    "  \"1\": {{\n",
    "    \"titulo\": \"Nombre del tema principal\",\n",
    "    \"subtemas\": [\n",
    "      \"Subtema 1.1\",\n",
    "      \"Subtema 1.2\",\n",
    "      \"Subtema 1.3\"\n",
    "    ]\n",
    "  }},\n",
    "  \"2\": {{\n",
    "    \"titulo\": \"Segundo tema principal\", \n",
    "    \"subtemas\": [\n",
    "      \"Subtema 2.1\",\n",
    "      \"Subtema 2.2\"\n",
    "    ]\n",
    "  }}\n",
    "}}\n",
    "\n",
    "IMPORTANTE: \n",
    "- Responde SOLO con el JSON\n",
    "- Asegúrate de que el JSON sea válido\n",
    "\n",
    "Lenguaje de respuesta: Español\n",
    "\"\"\"\n",
    "# - No incluyas explicaciones ni comentarios fuera del JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c402f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudyPlanner:\n",
    "  def __init__(self, model_name:str=GEMMA, temperature:float=0.8):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        model_name (str, optional): _description_. Defaults to GEMMA.\n",
    "        temperature (float, optional): _description_. Defaults to 0.8.\n",
    "    \"\"\"\n",
    "    self.model_name = model_name\n",
    "    self.temperature = temperature\n",
    "    \n",
    "    self.planning_prompt = planning_prompt\n",
    "    self.chat_prompt = ChatPromptTemplate.from_messages(\n",
    "      [\n",
    "        ('system', self.planning_prompt),\n",
    "        ('human', '''\n",
    "        SOLICITUD DEL ESTUDIANTE: {user_request}\n",
    "        \n",
    "        PERFIL DEL ESTUDIANTE:\n",
    "        - Fortalezas: {strengths}\n",
    "        - Debilidades: {weaknesses}\n",
    "        - Nivel de dificultad: {difficulty_level}\n",
    "        \n",
    "        Por favor, genera un plan de estudio personalizado.\n",
    "        ''')\n",
    "      ]\n",
    "    )\n",
    "    self.llm = OllamaLLM(model=model_name, temperature=temperature)\n",
    "    self.planner = self.chat_prompt | self.llm \n",
    "  \n",
    "  def generate_study_plan(self, user_request:str, student_profile:StudentProfile, attempts:int=4) -> Dict:\n",
    "    \"\"\"Genera un plan de estudio personalizado\n",
    "\n",
    "    Args:\n",
    "        user_request (str): lo que el estudiante quiere aprender\n",
    "        student_profile (StudentProfile): perfil académico del estudiante\n",
    "\n",
    "    Returns:\n",
    "        Dict: plan de estudio estructurado como diccionario JSON\n",
    "    \"\"\"\n",
    "    try:\n",
    "      profile_dict = student_profile.to_dict()\n",
    "      \n",
    "      response = self.planner.invoke({\n",
    "        'user_request': user_request,\n",
    "        'strengths': ', '.join(profile_dict['strengths']),\n",
    "        'weaknesses': ', '.join(profile_dict['weaknesses']),\n",
    "        'difficulty_level': profile_dict['difficulty_level'],\n",
    "      })\n",
    "      \n",
    "      # Limpiar la respuesta y parsear JSON\n",
    "      cleaned_response = self._clean_json_response(response)\n",
    "      study_plan = json.loads(cleaned_response)\n",
    "      \n",
    "      return study_plan\n",
    "      \n",
    "    except json.JSONDecodeError as e:\n",
    "      if attempts != 0: self.generate_study_plan(user_request, student_profile, attempts-1)\n",
    "      return {\n",
    "        \"error\": \"Error al parsear JSON del plan de estudio\",\n",
    "        \"raw_response\": response[:500] if 'response' in locals() else \"No response\",\n",
    "        \"json_error\": str(e),\n",
    "        \"response\": response\n",
    "      }\n",
    "    except Exception as e:\n",
    "      if attempts != 0: self.generate_study_plan(user_request, student_profile, attempts-1)\n",
    "      return {\n",
    "        \"error\": f\"Error al generar el plan de estudio: {str(e)}\",\n",
    "        \"response\": response\n",
    "      }\n",
    "  \n",
    "  def _clean_json_response(self, response:str) -> str:\n",
    "    \"\"\"Limpia la respuesta del LLM para extraer solo el JSON válido\n",
    "\n",
    "    Args:\n",
    "        response (str): _description_\n",
    "\n",
    "    Returns:\n",
    "        str: _description_\n",
    "    \"\"\"\n",
    "    # Buscar el JSON en la respuesta\n",
    "    json_start = response.find('{')\n",
    "    json_end = response.rfind('}') + 1\n",
    "        \n",
    "    if json_start != -1 and json_end != 0:\n",
    "      json_str = response[json_start:json_end]\n",
    "      return json_str\n",
    "\n",
    "    # Si no se encuentra JSON, intentar limpiar la respuesta completa\n",
    "    cleaned = response.strip()\n",
    "    if not cleaned.startswith('{'):\n",
    "      # Buscar patrones comunes y intentar extraer JSON\n",
    "      lines = cleaned.split('\\n')\n",
    "      json_lines = []\n",
    "      in_json = False\n",
    "      \n",
    "      for line in lines:\n",
    "        if '{' in line: \n",
    "          in_json = True\n",
    "        if in_json: \n",
    "          json_lines.append(line)\n",
    "        \n",
    "        if '}' in line and in_json: break\n",
    "      \n",
    "      cleaned = '\\n'.join(json_lines)\n",
    "        \n",
    "    return cleaned\n",
    "\n",
    "  def analyze_prerequisites(self, topic:str, student_profile:StudentProfile) -> List[str]:\n",
    "    \"\"\"Analiza qué prerequisitos necesita el estudiante para el tema solicitado\n",
    "\n",
    "    Args:\n",
    "        topic (str): _description_\n",
    "        student_profile (StudentProfile): _description_\n",
    "\n",
    "    Returns:\n",
    "        List[str]: _description_\n",
    "    \"\"\"\n",
    "    analysis_prompt = f\"\"\"\n",
    "    Analiza qué prerequisitos son necesarios para estudiar: {topic}\n",
    "        \n",
    "    Debilidades del estudiante: {', '.join(student_profile.weaknesses)}\n",
    "        \n",
    "    Identifica qué debilidades son críticas para este tema y devuelve una lista.\n",
    "    Responde solo con los prerequisitos, uno por línea.\n",
    "    \"\"\"\n",
    "        \n",
    "    try:\n",
    "      response = self.llm.invoke(analysis_prompt)\n",
    "      # Procesar la respuesta para extraer prerequisitos\n",
    "      prerequisites = [line.strip() for line in response.split('\\n') if line.strip()]\n",
    "      return prerequisites\n",
    "    except:\n",
    "      return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee6ebb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_prompt = \"\"\" \n",
    "Eres un asistente educativo amigable que ayuda a crear planes de estudio personalizados.\n",
    "\n",
    "Puedes:\n",
    "1. Recopilar información sobre el perfil académico del estudiante\n",
    "2. Entender qué quiere estudiar el usuario\n",
    "3. Generar planes de estudio personalizados\n",
    "4. Responder preguntas sobre los planes generados\n",
    "\n",
    "Sé conversacional, empático y educativo en tus respuestas.\n",
    "Lenguaje de respuesta: Español\n",
    "\"\"\"\n",
    "\n",
    "class ChatPlanner:\n",
    "  \"Bot conversacional que usa el agente de planificación\"\n",
    "  def __init__(self, model_name:str=GEMMA, temperature:float=0.8):\n",
    "    self.conversation_prompt = conversation_prompt\n",
    "    self.chat_prompt = ChatPromptTemplate.from_messages(\n",
    "      [\n",
    "        ('system', self.conversation_prompt),\n",
    "        MessagesPlaceholder(variable_name='memory'),\n",
    "        ('human', '{input}')\n",
    "      ]\n",
    "    )\n",
    "    self.llm = OllamaLLM(model=model_name, temperature=temperature)\n",
    "    self.memory: List[BaseMessage] = []\n",
    "    self.chatbot = self.chat_prompt | self.llm\n",
    "    \n",
    "    # Agente especializado en planificación\n",
    "    self.planner_agent = StudyPlanner(model_name, temperature=0.7)\n",
    "    \n",
    "    # Estado de la conversación\n",
    "    self.current_student_profile: Optional[StudentProfile] = None\n",
    "    self.current_topic: Optional[str] = None\n",
    "\n",
    "  def __call__(self, query:str, profile:StudentProfile):\n",
    "    \"Procesa la consulta del usuario\"\n",
    "    \n",
    "    # Detectar si el usuario quiere generar un plan\n",
    "    if self._is_plan_request(query):\n",
    "      self.current_student_profile = profile\n",
    "      return self._handle_plan_request(query)\n",
    "    \n",
    "    # Conversación normal\n",
    "    response = self.chatbot.invoke({\n",
    "      'input': query,\n",
    "      'memory': self.memory\n",
    "    })\n",
    "    \n",
    "    # Actualizar memoria\n",
    "    self.memory.append(HumanMessage(content=query))\n",
    "    self.memory.append(AIMessage(content=response))\n",
    "    \n",
    "    return response\n",
    "\n",
    "  def _is_plan_request(self, query:str) -> bool:\n",
    "    \"Detecta si la consulta es una solicitud de plan de estudio\"\n",
    "    keywords = ['plan', 'estudiar', 'aprender', 'esquema', 'cronograma', 'programa']\n",
    "    return any(keyword in query.lower() for keyword in keywords)\n",
    "  \n",
    "  def _handle_plan_request(self, query:str) -> str:\n",
    "    \"Maneja solicitudes de planes de estudio\"\n",
    "    if not self.current_student_profile:\n",
    "      return \"\"\"Para crear un plan de estudio personalizado, necesito conocer tu perfil académico.\n",
    "      \n",
    "      Por favor, proporciona la siguiente información:\n",
    "      1. Temas que dominas bien (fortalezas)\n",
    "      2. Temas que necesitas reforzar (debilidades)\n",
    "      3. Nivel de dificultad deseado\n",
    "      \"\"\"\n",
    "    \n",
    "    # Generar plan con el agente especializado\n",
    "    plan_dict = self.planner_agent.generate_study_plan(query, self.current_student_profile)\n",
    "    \n",
    "    # Convertir a JSON string formateado para mostrar al usuario\n",
    "    if isinstance(plan_dict, dict) and \"error\" not in plan_dict:\n",
    "      plan_json = json.dumps(plan_dict, indent=2, ensure_ascii=False)\n",
    "      response = f\"Plan de estudio generado:\\n\\n```json\\n{plan_json}\\n```\"\n",
    "    else:\n",
    "      # Si hay error, mostrar el diccionario de error\n",
    "      error_json = json.dumps(plan_dict, indent=2, ensure_ascii=False)\n",
    "      response = f\"Error al generar el plan:\\n\\n```json\\n{error_json}\\n```\"\n",
    "    \n",
    "    # Actualizar memoria\n",
    "    self.memory.append(HumanMessage(content=query))\n",
    "    self.memory.append(AIMessage(content=response))\n",
    "    \n",
    "    return response\n",
    "  \n",
    "  def get_last_plan(self) -> Optional[Dict]:\n",
    "    \"Retorna el último plan generado como diccionario\"\n",
    "    if not self.current_student_profile:\n",
    "      return None\n",
    "    # buscar en la memoria el último plan generado\n",
    "    for message in reversed(self.memory):\n",
    "      if isinstance(message, AIMessage) and \"Plan de estudio generado\" in message.content:\n",
    "        # extraer el JSON del mensaje\n",
    "        try:\n",
    "          start = message.content.find('{')\n",
    "          end = message.content.rfind('}') + 1\n",
    "          json_str = message.content[start:end]\n",
    "          return json.loads(json_str)\n",
    "        except:\n",
    "          continue\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b60e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = StudentProfile(\n",
    "  strengths=[\"programación básica\", \"lógica\", \"resolución de problemas\"],\n",
    "  weaknesses=[\"matrices\", \"álgebra lineal\", \"estadística\"],\n",
    "  difficulty_level=\"intermedio\"\n",
    ")\n",
    "request = \"Quiero aprender inteligencia artificial y machine learning\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30f20175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'titulo': 'Introducción a la Inteligencia Artificial y Machine Learning', 'subtemas': ['Conceptos básicos de IA y ML (qué es, aplicaciones, etc.)', 'Tipos de aprendizaje automático (supervisado, no supervisado, por refuerzo)', 'El proceso de aprendizaje automático (data, model, test, deploy)', 'Introducción a Python (para la programación básica)', 'Ejemplos prácticos de IA en el mundo real (reconocimiento de imágenes, procesamiento de lenguaje natural, etc.)']}, '2': {'titulo': 'Fundamentos de Machine Learning (Nivel Intermedio)', 'subtemas': ['Regresión Lineal y Logística: Implementación, interpretación y uso', 'Clasificación con Regresión Logística: Tipos, ventajas y desventajas', 'Clasificación con Algoritmos de K-Nearest Neighbors (KNN)', 'Evaluación de Modelos: Métricas de precisión, recall, F1-score, AUC-ROC', 'Selección de Características: Selección de características relevantes y eliminación de ruido']}, '3': {'titulo': 'Profundizando en el Aprendizaje Supervisado', 'subtemas': ['Evaluación de Modelos con Validación Cruzada (Cross-Validation)', 'Sobreajuste (Overfitting) y Subajuste (Underfitting) – Cómo identificar y mitigar', 'Técnicas de Regularización (L1 y L2)', 'Entrenamiento de Modelos: Ajuste de parámetros y optimización', 'Interpretación de Modelos:  Explicación de la importancia de las características']}, '4': {'titulo': 'Introducción a la Programación con Python', 'subtemas': ['Variables, Tipos de Datos, Operadores', 'Estructuras de Control: Bucles (for, while), Condicionales (if, else)', 'Listas, Tuplas, Diccionarios', 'Manejo de Archivos', 'Introducción a NumPy (para operaciones numéricas básicas)']}, '5': {'titulo': 'Modelos de Machine Learning Básicos (Nivel Intermedio)', 'subtemas': ['Regresión Lineal en Python', 'Clasificación con K-Nearest Neighbors (KNN) en Python', 'Evaluación de Modelos con Métricas de Precisión, Recall, F1-score']}}\n"
     ]
    }
   ],
   "source": [
    "planner = StudyPlanner()\n",
    "plan_response = planner.generate_study_plan(request, profile)\n",
    "print(plan_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
